{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR WINDOWS (your env must be called project-venv; if you choose another name add it in .gitignore)\n",
    "import subprocess\n",
    "\n",
    "# Set the execution policy\n",
    "subprocess.run([\"Set-ExecutionPolicy\", \"RemoteSigned\", \"-Scope\", \"Process\"], shell=True)\n",
    "\n",
    "# Activate the virtual environment\n",
    "subprocess.run([\"cd\", \".\\\\project-venv\\\\\"], shell=True)\n",
    "subprocess.run([\".\\\\Scripts\\\\Activate.ps1\"], shell=True)\n",
    "\n",
    "# Install requirements\n",
    "subprocess.run([\"pip\", \"install\", \"-r\", \"../requirements.txt\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "\n",
    "########## dlib_face_recognition_resnet_model_v1.dat ################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_1 = 'https://drive.google.com/uc?id=1tXD6dha1ZD4fceLWsGlI89t8HeHlkJYC' \n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_1 = '../Models/dlib_face_recognition_resnet_model_v1.dat'\n",
    "\n",
    "gdown.download(url_1, output_1, quiet=False)\n",
    "\n",
    "\n",
    "\n",
    "########## shape_predictor_68_face_landmarks.dat ###################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_2 = 'https://drive.google.com/uc?id=1dvIeJtWhObCgSYJt8WKnjIlHhw5Y9ioN'\n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_2 = '../Models/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "gdown.download(url_2, output_2, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ieeexplore.ieee.org/abstract/document/9659697?casa_token=zDD7lwwOig8AAAAA:KcIHhupXAXgiaB_C7A0uNDB7ehrsWNyovQdgDu9LmnwToOGU6akB_gjWTy7JCf4UdKK03Is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2a = nn.ReLU()\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2b = nn.ReLU()\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3a = nn.ReLU()\n",
    "        self.conv3b = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3b = nn.ReLU()\n",
    "        self.avgpool3 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        # verify the output size of conv2 and conv3\n",
    "        self.dummy_input = torch.randn(1, 1, 48, 48)\n",
    "        self.dummy_output_size = self._get_conv_output_size(self.dummy_input)\n",
    "        \n",
    "        # update fc1 units based on feature map size\n",
    "        self.fc1 = nn.Linear(self.dummy_output_size, 1024)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output_size(self, input_tensor):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(input_tensor)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout1(self.relu_fc1(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu_fc2(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**delete outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "2497\n",
      "disgust\n",
      "225\n",
      "fear\n",
      "2605\n",
      "happy\n",
      "4084\n",
      "neutral\n",
      "3127\n",
      "sad\n",
      "2811\n",
      "surprise\n",
      "2169\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_pixel_std(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return np.std(image)\n",
    "\n",
    "def remove_outliers_in_folder(folder_path, threshold):\n",
    "    counter = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        pixel_std = calculate_pixel_std(image_path)\n",
    "        \n",
    "        if pixel_std > threshold:\n",
    "            counter += 1\n",
    "            os.remove(image_path)\n",
    "    print(counter)\n",
    "\n",
    "# method based on mean and standard deviation\n",
    "def calculate_threshold_mean_std(values, factor=3):\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    threshold = mean + factor * std\n",
    "    return threshold\n",
    "\n",
    "# method based on k-means clustering\n",
    "def calculate_threshold_kmeans(values, k=1):\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(values.reshape(-1, 1))\n",
    "    centroids = kmeans.cluster_centers_.flatten()\n",
    "    threshold = np.mean(centroids)\n",
    "    return threshold\n",
    "\n",
    "emotions_folder_path = r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images\"\n",
    "pixel_stds = []\n",
    "for emotion in os.listdir(emotions_folder_path):\n",
    "    emotion_folder_path = os.path.join(emotions_folder_path, emotion)\n",
    "    for filename in os.listdir(emotion_folder_path):\n",
    "        image_path = os.path.join(emotion_folder_path, filename)\n",
    "        pixel_std = calculate_pixel_std(image_path)\n",
    "        pixel_stds.append(pixel_std)\n",
    "\n",
    "pixel_stds = np.array(pixel_stds)\n",
    "\n",
    "outlier_threshold = calculate_threshold_kmeans(pixel_stds)\n",
    "for emotion in os.listdir(emotions_folder_path):\n",
    "    print(emotion)\n",
    "    emotion_folder_path = os.path.join(emotions_folder_path, emotion)\n",
    "    remove_outliers_in_folder(emotion_folder_path, outlier_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**with over and under sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# transformation definition\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images'\n",
    "\n",
    "# create an instance of ImageFolder with the transformations\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# seed = 42\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# extract the labels and the indices of the dataset\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "\n",
    "# convert the list into a tensor\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# calculate the number of instances for each class\n",
    "counts = torch.bincount(labels)\n",
    "\n",
    "# calculate the weights for each class\n",
    "weights = 1.0 / counts.float()\n",
    "\n",
    "# create a weight vector for each index in the dataset\n",
    "sample_weights = weights[labels]\n",
    "\n",
    "# set the number of samples for the train set and the test set\n",
    "train_size = 2000 * 7 * 0.8 \n",
    "test_size = 2000 * 7 * 0.2 \n",
    "\n",
    "# crea un sampler per il train set and one for the test set\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(train_size))\n",
    "test_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(test_size))\n",
    "\n",
    "# create a dataloader for the train set and the test set with the corresponding samplers\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**without over and under sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images'\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.91060471534729, Test Accuracy: 0.18357142857142858\n",
      "Class: Angry, Precision: 0.0, Recall: 0.0\n",
      "Class: Disgust, Precision: 0.0, Recall: 0.0\n",
      "Class: Fear, Precision: 0.08333333333333333, Recall: 0.00510204081632653\n",
      "Class: Happy, Precision: 0.3333333333333333, Recall: 0.004796163069544364\n",
      "Class: Neutral, Precision: 0.0, Recall: 0.0\n",
      "Class: Sad, Precision: 0.15796019900497513, Recall: 0.9454094292803971\n",
      "Class: Surprise, Precision: 0.36338028169014086, Recall: 0.29930394431554525\n",
      "Total Accuracy: 0.18357142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 1.836012601852417, Test Accuracy: 0.2517857142857143\n",
      "Class: Angry, Precision: 0.18615751789976134, Recall: 0.18795180722891566\n",
      "Class: Disgust, Precision: 0.2617391304347826, Recall: 0.7132701421800948\n",
      "Class: Fear, Precision: 0.2857142857142857, Recall: 0.005154639175257732\n",
      "Class: Happy, Precision: 0.16666666666666666, Recall: 0.024752475247524754\n",
      "Class: Neutral, Precision: 0.0, Recall: 0.0\n",
      "Class: Sad, Precision: 0.1724137931034483, Recall: 0.060240963855421686\n",
      "Class: Surprise, Precision: 0.28361138370951916, Recall: 0.8005540166204986\n",
      "Total Accuracy: 0.2517857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 1.7682945728302002, Test Accuracy: 0.28464285714285714\n",
      "Class: Angry, Precision: 0.19856887298747763, Recall: 0.2775\n",
      "Class: Disgust, Precision: 0.3966789667896679, Recall: 0.5375\n",
      "Class: Fear, Precision: 0.16486486486486487, Recall: 0.1473429951690821\n",
      "Class: Happy, Precision: 0.25, Recall: 0.10837438423645321\n",
      "Class: Neutral, Precision: 0.18471337579617833, Recall: 0.21014492753623187\n",
      "Class: Sad, Precision: 0.0, Recall: 0.0\n",
      "Class: Surprise, Precision: 0.40969162995594716, Recall: 0.7099236641221374\n",
      "Total Accuracy: 0.28464285714285714\n",
      "Epoch [4/30], Loss: 1.8065354824066162, Test Accuracy: 0.2953571428571429\n",
      "Class: Angry, Precision: 0.0, Recall: 0.0\n",
      "Class: Disgust, Precision: 0.5282392026578073, Recall: 0.37767220902612825\n",
      "Class: Fear, Precision: 0.1893687707641196, Recall: 0.14285714285714285\n",
      "Class: Happy, Precision: 0.2222222222222222, Recall: 0.48128342245989303\n",
      "Class: Neutral, Precision: 0.19054878048780488, Recall: 0.3424657534246575\n",
      "Class: Sad, Precision: 0.0, Recall: 0.0\n",
      "Class: Surprise, Precision: 0.4214876033057851, Recall: 0.8010471204188482\n",
      "Total Accuracy: 0.2953571428571429\n",
      "Epoch [5/30], Loss: 1.7539987564086914, Test Accuracy: 0.32857142857142857\n",
      "Class: Angry, Precision: 0.19809069212410502, Recall: 0.21899736147757257\n",
      "Class: Disgust, Precision: 0.37037037037037035, Recall: 0.6796116504854369\n",
      "Class: Fear, Precision: 0.2054794520547945, Recall: 0.07751937984496124\n",
      "Class: Happy, Precision: 0.38666666666666666, Recall: 0.06921241050119331\n",
      "Class: Neutral, Precision: 0.2759433962264151, Recall: 0.2881773399014778\n",
      "Class: Sad, Precision: 0.25, Recall: 0.3526315789473684\n",
      "Class: Surprise, Precision: 0.5563063063063063, Recall: 0.592326139088729\n",
      "Total Accuracy: 0.32857142857142857\n",
      "Epoch [6/30], Loss: 1.7426389455795288, Test Accuracy: 0.3507142857142857\n",
      "Class: Angry, Precision: 0.23125, Recall: 0.44364508393285373\n",
      "Class: Disgust, Precision: 0.5224839400428265, Recall: 0.5965770171149144\n",
      "Class: Fear, Precision: 0.1696969696969697, Recall: 0.07368421052631578\n",
      "Class: Happy, Precision: 0.35135135135135137, Recall: 0.2846715328467153\n",
      "Class: Neutral, Precision: 0.25, Recall: 0.21951219512195122\n",
      "Class: Sad, Precision: 0.25961538461538464, Recall: 0.13012048192771083\n",
      "Class: Surprise, Precision: 0.5427435387673957, Recall: 0.6842105263157895\n",
      "Total Accuracy: 0.3507142857142857\n",
      "Epoch [7/30], Loss: 1.9489952325820923, Test Accuracy: 0.335\n",
      "Class: Angry, Precision: 0.2777777777777778, Recall: 0.09925558312655088\n",
      "Class: Disgust, Precision: 0.4930875576036866, Recall: 0.5376884422110553\n",
      "Class: Fear, Precision: 0.14285714285714285, Recall: 0.029612756264236904\n",
      "Class: Happy, Precision: 0.49606299212598426, Recall: 0.16710875331564987\n",
      "Class: Neutral, Precision: 0.2508250825082508, Recall: 0.1974025974025974\n",
      "Class: Sad, Precision: 0.22884012539184953, Recall: 0.5586734693877551\n",
      "Class: Surprise, Precision: 0.4206989247311828, Recall: 0.770935960591133\n",
      "Total Accuracy: 0.335\n",
      "Epoch [8/30], Loss: 1.7859688997268677, Test Accuracy: 0.38107142857142856\n",
      "Class: Angry, Precision: 0.3532608695652174, Recall: 0.15476190476190477\n",
      "Class: Disgust, Precision: 0.455743879472693, Recall: 0.6335078534031413\n",
      "Class: Fear, Precision: 0.3564356435643564, Recall: 0.09836065573770492\n",
      "Class: Happy, Precision: 0.3463114754098361, Recall: 0.4043062200956938\n",
      "Class: Neutral, Precision: 0.297153024911032, Recall: 0.4043583535108959\n",
      "Class: Sad, Precision: 0.25121951219512195, Recall: 0.25495049504950495\n",
      "Class: Surprise, Precision: 0.5438931297709924, Recall: 0.7178841309823678\n",
      "Total Accuracy: 0.38107142857142856\n",
      "Epoch [9/30], Loss: 1.7890644073486328, Test Accuracy: 0.4017857142857143\n",
      "Class: Angry, Precision: 0.3059490084985836, Recall: 0.288\n",
      "Class: Disgust, Precision: 0.6181818181818182, Recall: 0.601010101010101\n",
      "Class: Fear, Precision: 0.3125, Recall: 0.0585480093676815\n",
      "Class: Happy, Precision: 0.402321083172147, Recall: 0.5\n",
      "Class: Neutral, Precision: 0.3125, Recall: 0.29333333333333333\n",
      "Class: Sad, Precision: 0.2950108459869848, Recall: 0.33415233415233414\n",
      "Class: Surprise, Precision: 0.4601226993865031, Recall: 0.7425742574257426\n",
      "Total Accuracy: 0.4017857142857143\n",
      "Epoch [10/30], Loss: 1.7751448154449463, Test Accuracy: 0.4117857142857143\n",
      "Class: Angry, Precision: 0.2518939393939394, Recall: 0.3325\n",
      "Class: Disgust, Precision: 0.7035928143712575, Recall: 0.5919395465994962\n",
      "Class: Fear, Precision: 0.20572916666666666, Recall: 0.20308483290488433\n",
      "Class: Happy, Precision: 0.4547413793103448, Recall: 0.5222772277227723\n",
      "Class: Neutral, Precision: 0.3859060402684564, Recall: 0.2904040404040404\n",
      "Class: Sad, Precision: 0.35294117647058826, Recall: 0.16176470588235295\n",
      "Class: Surprise, Precision: 0.5190082644628099, Recall: 0.7733990147783252\n",
      "Total Accuracy: 0.4117857142857143\n",
      "Epoch [11/30], Loss: 1.8274818658828735, Test Accuracy: 0.42857142857142855\n",
      "Class: Angry, Precision: 0.3157894736842105, Recall: 0.13846153846153847\n",
      "Class: Disgust, Precision: 0.6955307262569832, Recall: 0.6303797468354431\n",
      "Class: Fear, Precision: 0.35, Recall: 0.15144230769230768\n",
      "Class: Happy, Precision: 0.45951417004048584, Recall: 0.5430622009569378\n",
      "Class: Neutral, Precision: 0.33706070287539935, Recall: 0.5355329949238579\n",
      "Class: Sad, Precision: 0.30057803468208094, Recall: 0.254278728606357\n",
      "Class: Surprise, Precision: 0.4672, Recall: 0.7724867724867724\n",
      "Total Accuracy: 0.42857142857142855\n",
      "Epoch [12/30], Loss: 1.7100796699523926, Test Accuracy: 0.4375\n",
      "Class: Angry, Precision: 0.40329218106995884, Recall: 0.2538860103626943\n",
      "Class: Disgust, Precision: 0.599609375, Recall: 0.7274881516587678\n",
      "Class: Fear, Precision: 0.3076923076923077, Recall: 0.07729468599033816\n",
      "Class: Happy, Precision: 0.4518348623853211, Recall: 0.5143603133159269\n",
      "Class: Neutral, Precision: 0.43455497382198954, Recall: 0.21227621483375958\n",
      "Class: Sad, Precision: 0.2637749120750293, Recall: 0.5859375\n",
      "Class: Surprise, Precision: 0.613882863340564, Recall: 0.6738095238095239\n",
      "Total Accuracy: 0.4375\n",
      "Epoch [13/30], Loss: 1.7165493965148926, Test Accuracy: 0.4567857142857143\n",
      "Class: Angry, Precision: 0.4008097165991903, Recall: 0.2385542168674699\n",
      "Class: Disgust, Precision: 0.6108695652173913, Recall: 0.6990049751243781\n",
      "Class: Fear, Precision: 0.327683615819209, Recall: 0.1514360313315927\n",
      "Class: Happy, Precision: 0.42214532871972316, Recall: 0.6272493573264781\n",
      "Class: Neutral, Precision: 0.42565597667638483, Recall: 0.35096153846153844\n",
      "Class: Sad, Precision: 0.30754716981132074, Recall: 0.41475826972010177\n",
      "Class: Surprise, Precision: 0.6193548387096774, Recall: 0.7164179104477612\n",
      "Total Accuracy: 0.4567857142857143\n",
      "Epoch [14/30], Loss: 1.6838867664337158, Test Accuracy: 0.48214285714285715\n",
      "Class: Angry, Precision: 0.3708133971291866, Recall: 0.41778975741239893\n",
      "Class: Disgust, Precision: 0.623352165725047, Recall: 0.7697674418604651\n",
      "Class: Fear, Precision: 0.3879310344827586, Recall: 0.2222222222222222\n",
      "Class: Happy, Precision: 0.4096185737976783, Recall: 0.6365979381443299\n",
      "Class: Neutral, Precision: 0.4956140350877193, Recall: 0.288265306122449\n",
      "Class: Sad, Precision: 0.36688311688311687, Recall: 0.27901234567901234\n",
      "Class: Surprise, Precision: 0.6270833333333333, Recall: 0.7359413202933985\n",
      "Total Accuracy: 0.48214285714285715\n",
      "Epoch [15/30], Loss: 1.7118127346038818, Test Accuracy: 0.4575\n",
      "Class: Angry, Precision: 0.31343283582089554, Recall: 0.32225063938618925\n",
      "Class: Disgust, Precision: 0.6277533039647577, Recall: 0.707196029776675\n",
      "Class: Fear, Precision: 0.2918454935622318, Recall: 0.17894736842105263\n",
      "Class: Happy, Precision: 0.6, Recall: 0.42028985507246375\n",
      "Class: Neutral, Precision: 0.36054421768707484, Recall: 0.5449871465295629\n",
      "Class: Sad, Precision: 0.35555555555555557, Recall: 0.26987951807228916\n",
      "Class: Surprise, Precision: 0.5868725868725869, Recall: 0.7450980392156863\n",
      "Total Accuracy: 0.4575\n",
      "Epoch [16/30], Loss: 1.6125743389129639, Test Accuracy: 0.47035714285714286\n",
      "Class: Angry, Precision: 0.3785900783289817, Recall: 0.34360189573459715\n",
      "Class: Disgust, Precision: 0.6485355648535565, Recall: 0.773067331670823\n",
      "Class: Fear, Precision: 0.2923076923076923, Recall: 0.10026385224274406\n",
      "Class: Happy, Precision: 0.5361596009975063, Recall: 0.5321782178217822\n",
      "Class: Neutral, Precision: 0.45964912280701753, Recall: 0.3195121951219512\n",
      "Class: Sad, Precision: 0.26126126126126126, Recall: 0.45194805194805193\n",
      "Class: Surprise, Precision: 0.6652078774617067, Recall: 0.7619047619047619\n",
      "Total Accuracy: 0.47035714285714286\n",
      "Epoch [17/30], Loss: 1.7722744941711426, Test Accuracy: 0.48\n",
      "Class: Angry, Precision: 0.3348115299334812, Recall: 0.39425587467362927\n",
      "Class: Disgust, Precision: 0.7421875, Recall: 0.7196969696969697\n",
      "Class: Fear, Precision: 0.38738738738738737, Recall: 0.11684782608695653\n",
      "Class: Happy, Precision: 0.48828125, Recall: 0.6476683937823834\n",
      "Class: Neutral, Precision: 0.545045045045045, Recall: 0.2944038929440389\n",
      "Class: Sad, Precision: 0.3161904761904762, Recall: 0.40389294403892945\n",
      "Class: Surprise, Precision: 0.5512605042016807, Recall: 0.7370786516853932\n",
      "Total Accuracy: 0.48\n",
      "Epoch [18/30], Loss: 1.6889092922210693, Test Accuracy: 0.48642857142857143\n",
      "Class: Angry, Precision: 0.39233038348082594, Recall: 0.3575268817204301\n",
      "Class: Disgust, Precision: 0.5708884688090737, Recall: 0.7844155844155845\n",
      "Class: Fear, Precision: 0.417910447761194, Recall: 0.06947890818858561\n",
      "Class: Happy, Precision: 0.536779324055666, Recall: 0.6443914081145584\n",
      "Class: Neutral, Precision: 0.40980392156862744, Recall: 0.495260663507109\n",
      "Class: Sad, Precision: 0.33047210300429186, Recall: 0.3710843373493976\n",
      "Class: Surprise, Precision: 0.689119170984456, Recall: 0.6927083333333334\n",
      "Total Accuracy: 0.48642857142857143\n",
      "Epoch [19/30], Loss: 1.5265761613845825, Test Accuracy: 0.5182142857142857\n",
      "Class: Angry, Precision: 0.3770197486535009, Recall: 0.5384615384615384\n",
      "Class: Disgust, Precision: 0.8158567774936062, Recall: 0.747072599531616\n",
      "Class: Fear, Precision: 0.3384146341463415, Recall: 0.2803030303030303\n",
      "Class: Happy, Precision: 0.5372093023255814, Recall: 0.5862944162436549\n",
      "Class: Neutral, Precision: 0.4691011235955056, Recall: 0.43717277486910994\n",
      "Class: Sad, Precision: 0.40789473684210525, Recall: 0.37349397590361444\n",
      "Class: Surprise, Precision: 0.7206703910614525, Recall: 0.6515151515151515\n",
      "Total Accuracy: 0.5182142857142857\n",
      "Epoch [20/30], Loss: 1.7650628089904785, Test Accuracy: 0.5085714285714286\n",
      "Class: Angry, Precision: 0.3727454909819639, Recall: 0.48186528497409326\n",
      "Class: Disgust, Precision: 0.7048458149779736, Recall: 0.7785888077858881\n",
      "Class: Fear, Precision: 0.32732732732732733, Recall: 0.2845953002610966\n",
      "Class: Happy, Precision: 0.5868263473053892, Recall: 0.5130890052356021\n",
      "Class: Neutral, Precision: 0.5171232876712328, Recall: 0.3561320754716981\n",
      "Class: Sad, Precision: 0.36693548387096775, Recall: 0.4375\n",
      "Class: Surprise, Precision: 0.7142857142857143, Recall: 0.7035175879396985\n",
      "Total Accuracy: 0.5085714285714286\n",
      "Epoch [21/30], Loss: 1.6119844913482666, Test Accuracy: 0.5292857142857142\n",
      "Class: Angry, Precision: 0.35984095427435386, Recall: 0.4826666666666667\n",
      "Class: Disgust, Precision: 0.6273408239700374, Recall: 0.8723958333333334\n",
      "Class: Fear, Precision: 0.44011976047904194, Recall: 0.3340909090909091\n",
      "Class: Happy, Precision: 0.5700483091787439, Recall: 0.6178010471204188\n",
      "Class: Neutral, Precision: 0.56, Recall: 0.37745098039215685\n",
      "Class: Sad, Precision: 0.5079365079365079, Recall: 0.31295843520782396\n",
      "Class: Surprise, Precision: 0.6168032786885246, Recall: 0.7487562189054726\n",
      "Total Accuracy: 0.5292857142857142\n",
      "Epoch [22/30], Loss: 1.6670100688934326, Test Accuracy: 0.5125\n",
      "Class: Angry, Precision: 0.4293193717277487, Recall: 0.3914081145584726\n",
      "Class: Disgust, Precision: 0.7869249394673123, Recall: 0.7756563245823389\n",
      "Class: Fear, Precision: 0.3562753036437247, Recall: 0.2146341463414634\n",
      "Class: Happy, Precision: 0.5547619047619048, Recall: 0.5943877551020408\n",
      "Class: Neutral, Precision: 0.3969335604770017, Recall: 0.5587529976019184\n",
      "Class: Sad, Precision: 0.3389830508474576, Recall: 0.27100271002710025\n",
      "Class: Surprise, Precision: 0.6403508771929824, Recall: 0.7807486631016043\n",
      "Total Accuracy: 0.5125\n",
      "Epoch [23/30], Loss: 1.7967231273651123, Test Accuracy: 0.49107142857142855\n",
      "Class: Angry, Precision: 0.3776595744680851, Recall: 0.370757180156658\n",
      "Class: Disgust, Precision: 0.5599250936329588, Recall: 0.7952127659574468\n",
      "Class: Fear, Precision: 0.47019867549668876, Recall: 0.1710843373493976\n",
      "Class: Happy, Precision: 0.5501113585746102, Recall: 0.5784543325526932\n",
      "Class: Neutral, Precision: 0.43564356435643564, Recall: 0.43564356435643564\n",
      "Class: Sad, Precision: 0.36363636363636365, Recall: 0.47804878048780486\n",
      "Class: Surprise, Precision: 0.7031700288184438, Recall: 0.6337662337662338\n",
      "Total Accuracy: 0.49107142857142855\n",
      "Epoch [24/30], Loss: 1.4940766096115112, Test Accuracy: 0.5178571428571429\n",
      "Class: Angry, Precision: 0.39759036144578314, Recall: 0.4074074074074074\n",
      "Class: Disgust, Precision: 0.7341176470588235, Recall: 0.7665847665847666\n",
      "Class: Fear, Precision: 0.3170731707317073, Recall: 0.07303370786516854\n",
      "Class: Happy, Precision: 0.5155393053016454, Recall: 0.7139240506329114\n",
      "Class: Neutral, Precision: 0.42035398230088494, Recall: 0.46798029556650245\n",
      "Class: Sad, Precision: 0.38164251207729466, Recall: 0.3979848866498741\n",
      "Class: Surprise, Precision: 0.6817204301075269, Recall: 0.7304147465437788\n",
      "Total Accuracy: 0.5178571428571429\n",
      "Epoch [25/30], Loss: 1.6466161012649536, Test Accuracy: 0.5317857142857143\n",
      "Class: Angry, Precision: 0.47079037800687284, Recall: 0.3586387434554974\n",
      "Class: Disgust, Precision: 0.7139737991266376, Recall: 0.8449612403100775\n",
      "Class: Fear, Precision: 0.34005037783375314, Recall: 0.36486486486486486\n",
      "Class: Happy, Precision: 0.5610972568578554, Recall: 0.5905511811023622\n",
      "Class: Neutral, Precision: 0.5273775216138329, Recall: 0.41309255079006774\n",
      "Class: Sad, Precision: 0.41081081081081083, Recall: 0.36626506024096384\n",
      "Class: Surprise, Precision: 0.6156716417910447, Recall: 0.7819905213270142\n",
      "Total Accuracy: 0.5317857142857143\n",
      "Epoch [26/30], Loss: 1.4122874736785889, Test Accuracy: 0.5460714285714285\n",
      "Class: Angry, Precision: 0.43596059113300495, Recall: 0.43703703703703706\n",
      "Class: Disgust, Precision: 0.7603305785123967, Recall: 0.8440366972477065\n",
      "Class: Fear, Precision: 0.3630573248407643, Recall: 0.2992125984251969\n",
      "Class: Happy, Precision: 0.57, Recall: 0.6951219512195121\n",
      "Class: Neutral, Precision: 0.5238095238095238, Recall: 0.4782608695652174\n",
      "Class: Sad, Precision: 0.3733681462140992, Recall: 0.3803191489361702\n",
      "Class: Surprise, Precision: 0.7283582089552239, Recall: 0.6455026455026455\n",
      "Total Accuracy: 0.5460714285714285\n",
      "Epoch [27/30], Loss: 1.7928305864334106, Test Accuracy: 0.515\n",
      "Class: Angry, Precision: 0.484593837535014, Recall: 0.4061032863849765\n",
      "Class: Disgust, Precision: 0.6883720930232559, Recall: 0.7769028871391076\n",
      "Class: Fear, Precision: 0.3485342019543974, Recall: 0.28232189973614774\n",
      "Class: Happy, Precision: 0.5421940928270043, Recall: 0.6314496314496314\n",
      "Class: Neutral, Precision: 0.46799116997792495, Recall: 0.513317191283293\n",
      "Class: Sad, Precision: 0.4497991967871486, Recall: 0.27860696517412936\n",
      "Class: Surprise, Precision: 0.5377358490566038, Recall: 0.7270408163265306\n",
      "Total Accuracy: 0.515\n",
      "Epoch [28/30], Loss: 1.5537341833114624, Test Accuracy: 0.5671428571428572\n",
      "Class: Angry, Precision: 0.5368421052631579, Recall: 0.3740831295843521\n",
      "Class: Disgust, Precision: 0.8363171355498721, Recall: 0.8034398034398035\n",
      "Class: Fear, Precision: 0.415625, Recall: 0.3481675392670157\n",
      "Class: Happy, Precision: 0.5180265654648957, Recall: 0.7338709677419355\n",
      "Class: Neutral, Precision: 0.56, Recall: 0.4688995215311005\n",
      "Class: Sad, Precision: 0.4282178217821782, Recall: 0.4271604938271605\n",
      "Class: Surprise, Precision: 0.6367112810707457, Recall: 0.8181818181818182\n",
      "Total Accuracy: 0.5671428571428572\n",
      "Epoch [29/30], Loss: 1.6352483034133911, Test Accuracy: 0.5517857142857143\n",
      "Class: Angry, Precision: 0.39955357142857145, Recall: 0.4986072423398329\n",
      "Class: Disgust, Precision: 0.7941888619854721, Recall: 0.8078817733990148\n",
      "Class: Fear, Precision: 0.32923832923832924, Recall: 0.35356200527704484\n",
      "Class: Happy, Precision: 0.6827956989247311, Recall: 0.5976470588235294\n",
      "Class: Neutral, Precision: 0.4934210526315789, Recall: 0.5844155844155844\n",
      "Class: Sad, Precision: 0.4607142857142857, Recall: 0.30424528301886794\n",
      "Class: Surprise, Precision: 0.6981132075471698, Recall: 0.7014218009478673\n",
      "Total Accuracy: 0.5517857142857143\n",
      "Epoch [30/30], Loss: 1.7150115966796875, Test Accuracy: 0.5189285714285714\n",
      "Class: Angry, Precision: 0.41040462427745666, Recall: 0.36883116883116884\n",
      "Class: Disgust, Precision: 0.7021739130434783, Recall: 0.8156565656565656\n",
      "Class: Fear, Precision: 0.37371134020618557, Recall: 0.3403755868544601\n",
      "Class: Happy, Precision: 0.6209677419354839, Recall: 0.6243243243243243\n",
      "Class: Neutral, Precision: 0.5572519083969466, Recall: 0.3501199040767386\n",
      "Class: Sad, Precision: 0.3389830508474576, Recall: 0.48661800486618007\n",
      "Class: Surprise, Precision: 0.6963350785340314, Recall: 0.6734177215189874\n",
      "Total Accuracy: 0.5189285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "\n",
    "num_classes = 7\n",
    "model = EmotionCNN(num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predicted.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_predicted)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Test Accuracy: {accuracy}')\n",
    "\n",
    "        precision = precision_score(all_labels, all_predicted, average=None)\n",
    "        recall = recall_score(all_labels, all_predicted, average=None)\n",
    "\n",
    "        for i, emotion in enumerate(your_label_mapping.values()):\n",
    "            print(f'Class: {emotion}, Precision: {precision[i]}, Recall: {recall[i]}')\n",
    "\n",
    "        print(f'Total Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**save and use the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\model0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**image emotion detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: Happy\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\model0.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_path = r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images\\happy\\Training_99183228.jpg\"  # Sostituisci con il percorso effettivo dell'immagine\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "input_image = transform(image).unsqueeze(0)\n",
    "input_image = input_image.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "\n",
    "_, predicted = torch.max(output, 1)\n",
    "predicted_emotion = your_label_mapping[predicted.item()]\n",
    "\n",
    "print(f'Predicted Emotion: {predicted_emotion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Live emotion detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\model0.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval() \n",
    "\n",
    "# initialize the face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# apply the transformations to the face image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "while True:\n",
    "    # read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # faces detection\n",
    "    faces = detector(frame)\n",
    "\n",
    "    # if there is at least one face detected, process the image\n",
    "    if len(faces) > 0:\n",
    "        # take only the first face\n",
    "        face = faces[0]\n",
    "        \n",
    "        # cut the face from the frame\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        face_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # apply the transformations to the face image\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB))\n",
    "        input_image = transform(pil_image).unsqueeze(0)  # Aggiunge una dimensione di batch\n",
    "        input_image = input_image.to(device)\n",
    "\n",
    "        # model prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(input_image)\n",
    "\n",
    "        # get the label predicted by the model\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_emotion = your_label_mapping[predicted.item()]\n",
    "\n",
    "        print(f'Predicted Emotion: {predicted_emotion}')\n",
    "\n",
    "    # show the frame with the face rectangle added\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    # wait for 2 seconds (time in milliseconds)\n",
    "    cv2.waitKey(2000)\n",
    "\n",
    "    # if q is pressed, terminate the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
