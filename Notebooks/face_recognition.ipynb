{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installing Requirements**\n",
    "\n",
    "Since the project is developed by different people, we will install all the requirements using the requirements.txt file which specifies all the packets' version that must be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Downloading Files from GDrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?export=download&confirm=pbef&id=1lF3pmEZvaQNvoV5bi7FQreS6l-iFU6J6 \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Recognition**\n",
    "\n",
    "Face recognition is a computer vision task that involves identifying and verifying a person's identity based on their facial features. This process can be broken down into these steps:\n",
    "\n",
    "1. **Detection**: Identifying faces in images or video frames.\n",
    "2. **Feature** Extraction: Capturing unique facial characteristics.\n",
    "3. **Representation**: Creating a distinctive template for each face.\n",
    "4. **Model Training**: Associating templates with known identities during training.\n",
    "5. **Matching**: Comparing a new face's template to stored ones for identification.\n",
    "6. **Decision**: Determining a match based on a similarity threshold.\n",
    "\n",
    "Nowadays, these steps are performed through deep learning models. In the following section we will provide a simple implementation through a pre-trained model and our paper implementation (further details in the next sections)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load all the user faces**\n",
    "\n",
    "All the registered users' face are saved into the UserFaces folder. We have to build our \"dataset\" of faces on which the recognition will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "detector = dlib.get_frontal_face_detector() # Load the pre-trained face detector from dlib\n",
    "face_recognizer = dlib.shape_predictor(\"../Models/shape_predictor_68_face_landmarks.dat\") # Load the pre-trained face recognition model \n",
    "\n",
    "# Initialize lists to store known faces and their corresponding names\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "base_directory = \"../UserFaces/\" # Directory containing user faces\n",
    "\n",
    "# Iterate through directories\n",
    "for user_directory in os.listdir(base_directory):\n",
    "\n",
    "    user_path = os.path.join(base_directory, user_directory)\n",
    "\n",
    "    # Iterate through face images in each user directory\n",
    "    for filename in os.listdir(user_path):\n",
    "        image_path = os.path.join(user_path, filename)\n",
    "\n",
    "        img = cv2.imread(image_path) # Read the image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Convert it into a gray scale image\n",
    "\n",
    "        faces = detector(gray) # Detect faces in the image (there will be only one face)\n",
    "\n",
    "        if faces:\n",
    "            face_landmarks = face_recognizer(img, faces[0]) # Obtain the landmarks\n",
    "\n",
    "            # Add face landmarks and user name to the lists\n",
    "            known_faces.append(face_landmarks)\n",
    "            known_names.append(user_directory)\n",
    "\n",
    "print(known_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-trained Model**\n",
    "\n",
    "This model is provided by the dlib library. Dlib's face recognition model is based on classical machine learning techniques rather than deep learning. It uses a combination of HOG (Histogram of Oriented Gradients) features and a SVM (Support Vector Machine) classifier to identify and recognize faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # Open a connection to the webcam (0 represents the default camera)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # Read a frame from the webcam\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the frame to grayscale for face detection\n",
    "    \n",
    "    faces = detector(gray) # Detect faces in the frame\n",
    "\n",
    "    # Iterate over detected faces\n",
    "    for face in faces:\n",
    "        landmarks = face_recognizer(frame, face) # Get facial landmarks\n",
    "\n",
    "        # Compare with known faces\n",
    "        for i, known_face in enumerate(known_faces):\n",
    "\n",
    "            if landmarks == known_face:\n",
    "                name = known_names[i]\n",
    "                print(f\"Hello, {name}!\")\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # Break the loop if the 'q' key is pressed\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
