{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installing Requirements**\n",
    "\n",
    "Since the project is developed by different people, we will install all the requirements using the requirements.txt file which specifies all the packets' version that must be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Downloading Files from GDrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os \n",
    "\n",
    "os.mkdir(\"../Models\")\n",
    "\n",
    "########## dlib_face_recognition_resnet_model_v1.dat ################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_1 = 'https://drive.google.com/uc?id=1tXD6dha1ZD4fceLWsGlI89t8HeHlkJYC' \n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_1 = '../Models/dlib_face_recognition_resnet_model_v1.dat'\n",
    "\n",
    "gdown.download(url_1, output_1, quiet=False)\n",
    "\n",
    "\n",
    "\n",
    "########## shape_predictor_68_face_landmarks.dat ###################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_2 = 'https://drive.google.com/uc?id=1dvIeJtWhObCgSYJt8WKnjIlHhw5Y9ioN'\n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_2 = '../Models/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "gdown.download(url_2, output_2, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Recognition**\n",
    "\n",
    "Face recognition is a computer vision task that involves identifying and verifying a person's identity based on their facial features. This process can be broken down into these steps:\n",
    "\n",
    "1. **Detection**: Identifying faces in images or video frames.\n",
    "2. **Feature** Extraction: Capturing unique facial characteristics.\n",
    "3. **Representation**: Creating a distinctive template for each face.\n",
    "4. **Model Training**: Associating templates with known identities during training.\n",
    "5. **Matching**: Comparing a new face's template to stored ones for identification.\n",
    "6. **Decision**: Determining a match based on a similarity threshold.\n",
    "\n",
    "Nowadays, these steps are performed through deep learning models. In the following section we will provide a simple implementation through a pre-trained model and our paper implementation (further details in the next sections)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pre-trained Dlib's Model**\n",
    "\n",
    "The following technique is a simple face recognition implemented using dlib's pre-trained models. The face detector is implemented using standard computer vision techniques and classical machine learning models (such as SVM, KNN, ...). The aim of this part is to provide a simple solution for the problem in order to compare the more sophisticated implementation provided by the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create List of Known Faces\n",
    "This code provides a set of functions for face detection, facial landmarks computation, facial encoding, and learning known faces. These functions are designed to be used in a facial recognition system.\n",
    "\n",
    "- **`face_rects`**: Detects faces in an input image using a specified face detector model and returns a list of rectangles representing the detected faces.\n",
    "\n",
    "- **`face_landmarks`**: Computes facial landmarks for each detected face in an input image using a facial landmark predictor model.\n",
    "\n",
    "- **`face_encodings`**: Computes facial encodings (features) for each detected face in an input image using a face encoding model.\n",
    "\n",
    "- **`learn_faces`**: Learns and stores facial encodings for known faces. It iterates through a directory containing user faces, reads face images, computes face encodings, and stores them in a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import threading\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def face_rects(image, face_detector):\n",
    "\n",
    "    \"\"\"\n",
    "    Detects faces in the input image using a face detector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - face_detector: Face detector model.\n",
    "\n",
    "    Returns:\n",
    "    - rects: List of rectangles representing the detected faces.\n",
    "    \"\"\"\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert the image to grayscale\n",
    "    rects = face_detector(gray, 1) # Detect faces in the grayscale image\n",
    "    return rects\n",
    "\n",
    "\n",
    "\n",
    "def face_landmarks(image, shape_predictor, face_detector):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes facial landmarks for each face in the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - shape_predictor: Facial landmark predictor model.\n",
    "    - face_detector: Face detector model.\n",
    "\n",
    "    Returns:\n",
    "    - List of facial landmarks for each detected face.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the face landmarks for each face in the image\n",
    "    return [shape_predictor(image, face_rect) for face_rect in face_rects(image, face_detector)]\n",
    "\n",
    "\n",
    "\n",
    "def face_encodings(image, face_encoder, shape_predictor, face_detector):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes facial encodings (features) for each face in the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - face_encoder: Face encoding model.\n",
    "    - shape_predictor: Facial landmark predictor model.\n",
    "    - face_detector: Face detector model.\n",
    "\n",
    "    Returns:\n",
    "    - List of facial encodings for each detected face.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the facial embeddings for each face (128-d vector that describes the face in an image)\n",
    "    return [np.array(face_encoder.compute_face_descriptor(image, face_landmark)) for face_landmark in face_landmarks(image, shape_predictor, face_detector)]\n",
    "\n",
    "\n",
    "\n",
    "def learn_faces(face_detector, shape_predictor, face_encoder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Learns and stores facial encodings for known faces.\n",
    "\n",
    "    Parameters:\n",
    "    - face_detector: Face detector model.\n",
    "    - shape_predictor: Facial landmark predictor model.\n",
    "    - face_encoder: Face encoding model.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing facial encodings for each known user.\n",
    "    \"\"\"\n",
    "\n",
    "    known_faces = {}\n",
    "    base_directory = \"../UserFaces/\"  # Directory containing user faces\n",
    "\n",
    "    # Iterate through directories\n",
    "    for user_name in os.listdir(base_directory):\n",
    "        user_path = os.path.join(base_directory, user_name)\n",
    "\n",
    "        # Iterate through face images in each user directory\n",
    "        for filename in os.listdir(user_path):\n",
    "            image_path = os.path.join(user_path, filename)\n",
    "\n",
    "            img = cv2.imread(image_path)  # Read the image\n",
    "            new_encodings = face_encodings(img, face_encoder, shape_predictor, face_detector) # Get the embeddings\n",
    "\n",
    "            encodings = known_faces.get(user_name, [])\n",
    "            # Add the embeddings to the already saved ones\n",
    "            encodings.extend(new_encodings)\n",
    "            known_faces[user_name] = encodings\n",
    "\n",
    "    print(known_faces.keys())\n",
    "\n",
    "    return known_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize the user\n",
    "\n",
    "This code performs real-time face recognition using a webcam. It utilizes the dlib library for face detection, facial landmarks computation, and face encoding.\n",
    "\n",
    "- **`nb_of_matches`**: Calculates the number of matches between an unknown face encoding and the encodings in the database. It computes the Euclidean distance and checks for matches based on a specified threshold.\n",
    "\n",
    "- **`face_recognition`**:  Performs real-time face recognition using the webcam. The code initializes face detection, facial landmarks, and face encoding models from dlib. It continuously captures frames from the webcam, computes the face encodings, compares them with known faces, and determines the recognized username.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_of_matches(known_encodings, unknown_encoding):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the number of matches between the unknown face encoding and the encodings in the database.\n",
    "\n",
    "    Parameters:\n",
    "    - known_encodings: Dictionary containing facial encodings for each known user.\n",
    "    - unknown_encoding: Facial encoding for the unknown face.\n",
    "\n",
    "    Returns:\n",
    "    - Number of matches (faces with a distance less than or equal to a threshold) for each known user.\n",
    "    \"\"\"\n",
    "\n",
    "    distances = np.linalg.norm(known_encodings - unknown_encoding, axis=1)\n",
    "    small_distances = distances <= 0.8  # Keep only the distances that are less than the threshold\n",
    "    return sum(small_distances)\n",
    "\n",
    "\n",
    "\n",
    "def set_stop_thread():\n",
    "\n",
    "    \"\"\"\n",
    "    Thread function to set the stop_thread variable to True after 10 seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    global stop_thread\n",
    "    time.sleep(10)  # Wait for 10 seconds\n",
    "    with lock:\n",
    "        stop_thread = True\n",
    "\n",
    "\n",
    "\n",
    "def face_recognition(known_faces: dict, face_detector, shape_predictor, face_encoder):\n",
    "\n",
    "    \"\"\"\n",
    "    Performs real-time face recognition using the webcam.\n",
    "\n",
    "    Returns:\n",
    "    - Recognized username.\n",
    "    \"\"\"\n",
    "\n",
    "    username = \"Unknown\"\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Open a connection to the webcam \n",
    "    \n",
    "    global stop_thread\n",
    "    stop_thread = False\n",
    "\n",
    "    global lock \n",
    "    lock = threading.Lock()\n",
    "\n",
    "    # Start the thread that sets the stop_thread variable after 10 seconds\n",
    "    stop_thread_thread = threading.Thread(target=set_stop_thread)\n",
    "    stop_thread_thread.start()\n",
    "\n",
    "    while True:\n",
    "        with lock:\n",
    "            # Check if the stop_thread variable is set to True\n",
    "            if stop_thread:\n",
    "                break\n",
    "\n",
    "        ret, frame = cap.read()  # Read a frame from the webcam\n",
    "\n",
    "        # Get the face encodings of the unknown face\n",
    "        frame_encodings = face_encodings(frame, face_detector=face_detector, face_encoder=face_encoder, shape_predictor=shape_predictor)\n",
    "\n",
    "        for encoding in frame_encodings:\n",
    "            counts = {}\n",
    "\n",
    "            for (name, known_encodings) in known_faces.items():\n",
    "                # Compare the encodings between every face in the user dataset and the current one\n",
    "                counts[name] = nb_of_matches(known_encodings, encoding)\n",
    "            \n",
    "            if all(count == 0 for count in counts.values()):\n",
    "                # If there are no matches, the user is unknown\n",
    "                username = \"Unknown\"\n",
    "            else:\n",
    "                # Pick the user with the highest number of matches\n",
    "                username = max(counts, key=counts.get)\n",
    "                return username\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    stop_thread_thread.join()  # Wait for the stop_thread thread to finish\n",
    "\n",
    "    return username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Usage Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(\"../Models/shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"../Models/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "known_faces = learn_faces(face_detector, shape_predictor, face_encoder)\n",
    "\n",
    "username = face_recognition(known_faces, face_detector, shape_predictor, face_encoder)\n",
    "\n",
    "print(username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
