{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import dlib\n",
    "\n",
    "# Thread-safe variable\n",
    "stop_thread = False\n",
    "lock = threading.Lock()\n",
    "\n",
    "def set_stop_thread():\n",
    "    global stop_thread\n",
    "    time.sleep(10)  # Wait for 10 seconds\n",
    "    with lock:\n",
    "        stop_thread = True\n",
    "\n",
    "def face_registration(username: str):\n",
    "    # Start the thread that sets the stop_thread variable after 10 seconds\n",
    "    stop_thread_thread = threading.Thread(target=set_stop_thread)\n",
    "    stop_thread_thread.start()\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    output_directory = f'../UserFaces/{username}/'\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    video_path = os.path.join(output_directory, 'video.avi')\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "    videoWriter = cv2.VideoWriter(video_path, fourcc, 30.0, (640, 480), True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        if ret:\n",
    "            cv2.imshow('Webcam', frame)\n",
    "            videoWriter.write(frame)\n",
    "\n",
    "        with lock:\n",
    "            if stop_thread:\n",
    "                break\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    videoWriter.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    stop_thread_thread.join()  # Wait for the stop_thread thread to finish\n",
    "\n",
    "    detect_faces(username)\n",
    "    #os.remove(f'../UserFaces/{username}/video.avi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    face_detector = dlib.get_frontal_face_detector() # Model used to get detect faces\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the image to grayscale\n",
    "    faces = face_detector(gray, 1) # Detect faces in the grayscale image\n",
    "\n",
    "    if faces:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def detect_faces(username:str):\n",
    "\n",
    "    output_directory = os.path.join('..', 'UserFaces', username)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(output_directory, 'video.avi'))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    valid_frames = []\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"End of video.\")\n",
    "            break\n",
    "\n",
    "        if(valid_frames != [] and frame_count - valid_frames[-1] < 10 and frame_count // 10 == valid_frames[-1] // 10):\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        if(process_frame(frame)): # Save the face in the folder\n",
    "            valid_frames.append(frame_count)\n",
    "            print(f'Valid frame detected: {frame_count}')\n",
    "            cv2.imwrite(os.path.join(output_directory, f'face_{len(valid_frames)}.png'), frame)\n",
    "\n",
    "        frame_count += 1 \n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition():\n",
    "\n",
    "    username = \"Unknown\"\n",
    "\n",
    "    return username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.game_communicator import GameCommunicator\n",
    "\n",
    "game_communicator = GameCommunicator()\n",
    "game_communicator.wait_for_connection()\n",
    "\n",
    "while True:\n",
    "\n",
    "    msg = game_communicator.receive_from_game()\n",
    "    msg = msg.split(':')\n",
    "\n",
    "    if msg[0] == \"face_registration\":\n",
    "        username = msg[1]\n",
    "        #face_registration(username)\n",
    "        detect_faces(username)\n",
    "\n",
    "        game_communicator.send_to_game(\"success\")\n",
    "\n",
    "    if msg == \"face_recognition\":\n",
    "\n",
    "        username = face_recognition()\n",
    "        game_communicator.send_to_game(username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
