{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Game Management**\n",
    "\n",
    "In this notebook, we will implement the game management system, including communication with the game and all associated mechanisms. The Python code handles the computer vision aspect of the project, implementing:\n",
    "\n",
    "- Face Registration and Recognition, used for users' signup and login.\n",
    "- Emotion Recognition, to adjust the difficulty of the game based on the player's emotions.\n",
    "- Body Tracking, to control the virtual character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Face Registration (User Signup)**\n",
    "\n",
    "This section involves recording a 10-second video from the webcam. The frames composing the video will be processed to identify a feasible one in which a face is detected. This process utilizes dlib's face detector, known for its high precision and accuracy. The frames deemed valid will be stored in the UserFaces directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Acquisition\n",
    "\n",
    "This Python script captures video from a webcam, saves it to a file, and performs face detection using OpenCV and dlib. The threaded design sets a stop flag after 10 seconds to gracefully terminate the video capture loop. The recorded video frames are stored in a directory named after the provided username. Face detection is executed on the captured video, and the temporary file is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Thread-safe variable\n",
    "stop_thread = False\n",
    "lock = threading.Lock()\n",
    "\n",
    "def set_stop_thread():\n",
    "\n",
    "    \"\"\"\n",
    "    Thread function to set the stop_thread variable to True after 10 seconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    global stop_thread\n",
    "    time.sleep(10)  # Wait for 10 seconds\n",
    "    with lock:\n",
    "        stop_thread = True\n",
    "\n",
    "def video_acquisition(username: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Capture video from the webcam, save it to a file, and perform face detection.\n",
    "\n",
    "    Parameters:\n",
    "    - username: User identifier for creating output folder\n",
    "\n",
    "    Returns:\n",
    "    - True if faces are detected, False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Start the thread that sets the stop_thread variable after 10 seconds\n",
    "    stop_thread_thread = threading.Thread(target=set_stop_thread)\n",
    "    stop_thread_thread.start()\n",
    "\n",
    "    # Ensure the directory exists for storing face images\n",
    "    output_directory = f'../UserFaces/{username}/'\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    video_path = os.path.join(output_directory, 'video.avi') # Define the path for storing the captured video\n",
    "\n",
    "    capture = cv2.VideoCapture(0) # Open a connection to the webcam\n",
    "\n",
    "    # Define the codec and create a VideoWriter object to save the video\n",
    "    fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "    videoWriter = cv2.VideoWriter(video_path, fourcc, 30.0, (640, 480), True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read() # Read a frame from the webcam\n",
    "\n",
    "        if ret:\n",
    "            cv2.imshow('Webcam', frame)  # Display the frame from the webcam\n",
    "            videoWriter.write(frame) # Write the frame to the video file\n",
    "\n",
    "        with lock:\n",
    "            # Check if the stop_thread variable is set to True\n",
    "            if stop_thread:\n",
    "                break\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    # Release the capture and videoWriter objects\n",
    "    capture.release()\n",
    "    videoWriter.release()\n",
    "\n",
    "    cv2.destroyAllWindows() # Close the OpenCV window\n",
    "    stop_thread_thread.join() # Wait for the stop_thread thread to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Proccesing\n",
    "\n",
    "The process_frame function detects faces in a single input frame using the dlib library, returning True if faces are found and False otherwise. The detect_faces function processes a video, saves frames with detected faces, and returns True if a sufficient number of faces are detected across frames, otherwise False. Using these functions we can simply create a 'database' for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "\n",
    "    \"\"\"\n",
    "    Process a single frame to detect faces.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: Input frame (image)\n",
    "\n",
    "    Returns:\n",
    "    - True if faces are detected, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    face_detector = dlib.get_frontal_face_detector() # Initialize the face detector using dlib\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "    faces = face_detector(gray, 1) # Detect faces in the grayscale image\n",
    "\n",
    "    if faces: return True  # Faces detected\n",
    "\n",
    "    return False  # No faces detected\n",
    "\n",
    "def detect_faces(username: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Process a video to detect and save faces in frames.\n",
    "\n",
    "    Parameters:\n",
    "    - username: User identifier used for output folder\n",
    "\n",
    "    Returns:\n",
    "    - True if faces are detected in enough frames, False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    output_directory = os.path.join('..', 'UserFaces', username) # Set the output directory for storing face images\n",
    "    cap = cv2.VideoCapture(os.path.join(output_directory, 'video.avi')) # Open the video file for processing\n",
    "\n",
    "    # Check if the video file is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    last_valid_frame = None  # Index of the last valid frame\n",
    "    valid_frames = 0 # Number of valid frames\n",
    "    frame_count = 0\n",
    "    total_num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Loop through each frame in the video\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read() # Read the next frame from the video\n",
    "\n",
    "        # Check if the end of the video is reached\n",
    "        if not ret:\n",
    "            print(\"End of video.\")\n",
    "            break\n",
    "\n",
    "        # Calculate the percentage completion\n",
    "        percentage_completion = (frame_count / total_num_of_frames) * 100\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Progress: {int(percentage_completion)}%\")\n",
    "            game_communicator.send_to_game(f'{int(percentage_completion)}')\n",
    "\n",
    "        # Skip frames if they are too close to the previous valid frame\n",
    "        if (last_valid_frame and frame_count // 15 == last_valid_frame // 15):\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # Process the frame to detect faces\n",
    "        if process_frame(frame):\n",
    "            # Save the face in the output folder\n",
    "            last_valid_frame = frame_count\n",
    "            valid_frames += 1\n",
    "            cv2.imwrite(os.path.join(output_directory, f'face_{valid_frames}.png'), frame)\n",
    "\n",
    "        frame_count += 1  # Increment the frame count\n",
    "\n",
    "    cap.release() # Release the video capture object\n",
    "\n",
    "    print(f'{valid_frames} Valid frames found!')\n",
    "\n",
    "    # Check if an insufficient number of valid frames are detected\n",
    "    if valid_frames < 10:\n",
    "        return False  # Not enough valid frames\n",
    "\n",
    "    return True  # Faces detected in enough frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Registration\n",
    "\n",
    "Through this function we can put all the pieces toghether, hence acquire the video and save the detected faces into the user's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_registration(username: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Main function for face registration.\n",
    "\n",
    "    Parameters:\n",
    "    - username: User identifier for creating output folder\n",
    "\n",
    "    Returns:\n",
    "    - Result of face detection (True if faces are detected, False otherwise)\n",
    "    \"\"\"\n",
    "\n",
    "    video_acquisition(username)\n",
    "\n",
    "    # Perform face detection on the captured video\n",
    "    result = detect_faces(username)\n",
    "\n",
    "    # Remove the temporary video file\n",
    "    os.remove(os.path.join('..', 'UserFaces', username, 'video.avi'))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Face Recognition (User Login)**\n",
    "\n",
    "For the face recognition part, we will import from the Modules the face_recognition function. Note that the 'face_recognition.py' is the Notebook 'face_recognition.ipynb' converted into a Python file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.face_recognition import face_recognition \n",
    "from Modules.face_recognition import learn_faces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Game Communication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\Desktop\\ComputerVisionProject\\Notebooks\\game_management.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Desktop/ComputerVisionProject/Notebooks/game_management.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m shape_predictor \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39mshape_predictor(\u001b[39m\"\u001b[39m\u001b[39m../Models/shape_predictor_68_face_landmarks.dat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Desktop/ComputerVisionProject/Notebooks/game_management.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m face_encoder \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39mface_recognition_model_v1(\u001b[39m\"\u001b[39m\u001b[39m../Models/dlib_face_recognition_resnet_model_v1.dat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/Desktop/ComputerVisionProject/Notebooks/game_management.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m known_faces \u001b[39m=\u001b[39m learn_faces(face_detector, shape_predictor, face_encoder)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Desktop/ComputerVisionProject/Notebooks/game_management.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m game_communicator \u001b[39m=\u001b[39m GameCommunicator()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/Desktop/ComputerVisionProject/Notebooks/game_management.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m game_communicator\u001b[39m.\u001b[39mwait_for_connection()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learn_faces' is not defined"
     ]
    }
   ],
   "source": [
    "from Modules.game_communicator import GameCommunicator\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(\"../Models/shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"../Models/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "known_faces = learn_faces(face_detector, shape_predictor, face_encoder)\n",
    "\n",
    "game_communicator = GameCommunicator()\n",
    "game_communicator.wait_for_connection()\n",
    "\n",
    "while True:\n",
    "\n",
    "    msg = game_communicator.receive_from_game()\n",
    "    msg = msg.split(':')\n",
    "\n",
    "    if msg[0] == \"face_registration\":\n",
    "        username = msg[1]\n",
    "        if(face_registration(username)):\n",
    "            game_communicator.send_to_game(\"success\")\n",
    "        else:\n",
    "            game_communicator.send_to_game(\"fail\")\n",
    "\n",
    "    if msg[0] == \"face_recognition\":\n",
    "\n",
    "        username = face_recognition(known_faces, face_detector, shape_predictor, face_encoder)\n",
    "        game_communicator.send_to_game(username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
