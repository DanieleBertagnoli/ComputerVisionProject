{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR WINDOWS (your env must be called project-venv; if you choose another name add it in .gitignore)\n",
    "import subprocess\n",
    "\n",
    "# Set the execution policy\n",
    "subprocess.run([\"Set-ExecutionPolicy\", \"RemoteSigned\", \"-Scope\", \"Process\"], shell=True)\n",
    "\n",
    "# Activate the virtual environment\n",
    "subprocess.run([\"cd\", \".\\\\project-venv\\\\\"], shell=True)\n",
    "subprocess.run([\".\\\\Scripts\\\\Activate.ps1\"], shell=True)\n",
    "\n",
    "# Install requirements\n",
    "subprocess.run([\"pip\", \"install\", \"-r\", \"../requirements.txt\"], shell=True)\n",
    "subprocess.run([\"pip\", \"install\", \"-r\", \"../emotions_requirements.txt\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "\n",
    "########## dlib_face_recognition_resnet_model_v1.dat ################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_1 = 'https://drive.google.com/uc?id=1tXD6dha1ZD4fceLWsGlI89t8HeHlkJYC' \n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_1 = '../Models/dlib_face_recognition_resnet_model_v1.dat'\n",
    "\n",
    "gdown.download(url_1, output_1, quiet=False)\n",
    "\n",
    "\n",
    "\n",
    "########## shape_predictor_68_face_landmarks.dat ###################\n",
    "\n",
    "# URL del file di Google Drive\n",
    "url_2 = 'https://drive.google.com/uc?id=1dvIeJtWhObCgSYJt8WKnjIlHhw5Y9ioN'\n",
    "\n",
    "# Percorso in cui si desidera salvare il file scaricato\n",
    "output_2 = '../Models/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "gdown.download(url_2, output_2, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from PIL import Image\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wandb login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key='d29d51017f4231b5149d36ad242526b374c9c60a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper implementation 1\n",
    "https://ieeexplore.ieee.org/abstract/document/9659697?casa_token=zDD7lwwOig8AAAAA:KcIHhupXAXgiaB_C7A0uNDB7ehrsWNyovQdgDu9LmnwToOGU6akB_gjWTy7JCf4UdKK03Is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset augmenting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# cycle through emotions\n",
    "for emotion in emotions:\n",
    "    # path of the folder containing the images\n",
    "    folder_path = fr\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images\\{emotion}\"\n",
    "    output_folder_path = fr\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_images\\{emotion}_augmented\"\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # list of images in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # define transformations inside the apply_transformations function\n",
    "    def apply_transformations(image):\n",
    "        # horizontal_flip\n",
    "        flipped_horizontal = cv2.flip(image, 1)\n",
    "\n",
    "        # vertical flip\n",
    "        flipped_vertical = cv2.flip(image, 0)\n",
    "\n",
    "        # Zoom\n",
    "        zoom_factor = random.uniform(0.8, 1.2)\n",
    "        height, width = image.shape[:2]\n",
    "        zoomed_image = cv2.resize(image, (int(width * zoom_factor), int(height * zoom_factor)))\n",
    "\n",
    "        # translation\n",
    "        tx = random.randint(-10, 10)\n",
    "        ty = random.randint(-10, 10)\n",
    "        translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        translated_image = cv2.warpAffine(image, translation_matrix, (width, height))\n",
    "\n",
    "        # contrast and brightness control\n",
    "        alpha = random.uniform(0.8, 1.2)\n",
    "        beta = random.randint(-35, 35)\n",
    "        adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "        # elastic transformation\n",
    "        elastic_image = elastic_transform(image, alpha=random.randint(6, 14), sigma=random.uniform(1.1, 2.0))\n",
    "\n",
    "        return [image, translated_image, flipped_horizontal, zoomed_image, adjusted_image, elastic_image] #forse togliere flipped vertical\n",
    "\n",
    "    def elastic_transform(image, alpha, sigma):\n",
    "        random_state = np.random.RandomState(None)\n",
    "        shape = image.shape\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dz = np.zeros_like(dx)\n",
    "\n",
    "        x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "        indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z + dz, (-1, 1))\n",
    "\n",
    "        distorted_image = map_coordinates(image, indices, order=1, mode='reflect')\n",
    "        distorted_image = distorted_image.reshape(image.shape)\n",
    "\n",
    "        return distorted_image\n",
    "\n",
    "    # apply data augmentation\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        augmented_images = apply_transformations(image)\n",
    "\n",
    "        # save new images\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        for i, augmented_image in enumerate(augmented_images):\n",
    "            output_file_path = os.path.join(output_folder_path, f\"{base_name}_aug_{i}.jpg\")\n",
    "            cv2.imwrite(output_file_path, augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2a = nn.ReLU()\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2b = nn.ReLU()\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3a = nn.ReLU()\n",
    "        self.conv3b = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3b = nn.ReLU()\n",
    "        self.avgpool3 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        # verify the output size of conv2 and conv3\n",
    "        self.dummy_input = torch.randn(1, 1, 48, 48)\n",
    "        self.dummy_output_size = self._get_conv_output_size(self.dummy_input)\n",
    "        \n",
    "        # update fc1 units based on feature map size\n",
    "        self.fc1 = nn.Linear(self.dummy_output_size, 1024)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output_size(self, input_tensor):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(input_tensor)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout1(self.relu_fc1(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu_fc2(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances_over_under_sampling_ = 30000\n",
    "batch_size_ = 48\n",
    "epochs_ = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**delete outliers with dbscan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_std(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return np.std(image)\n",
    "\n",
    "def remove_outliers_dbscan(folder_path, eps, min_samples):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        pixel_std = calculate_pixel_std(image_path)\n",
    "        images.append([pixel_std])\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    # dbscan to identify outliers\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(images)\n",
    "\n",
    "    # remove outliers\n",
    "    counter = 0\n",
    "    for i, (label, image) in enumerate(zip(labels, os.listdir(folder_path))):\n",
    "        if label == -1:  \n",
    "            image_path = os.path.join(folder_path, image)\n",
    "            os.remove(image_path)\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "\n",
    "# DBSCAN configuration\n",
    "dbscan_eps = 0.4  # search radius\n",
    "dbscan_min_samples = 15  # minimum number of samples required for a cluster\n",
    "\n",
    "emotions_folder_path = r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\"\n",
    "\n",
    "\n",
    "for emotion in os.listdir(emotions_folder_path):\n",
    "    emotion_folder_path = os.path.join(emotions_folder_path, emotion)\n",
    "    print(emotion)\n",
    "    \n",
    "    if emotion == 'disgust':\n",
    "        tmp_folder_path = emotion_folder_path \n",
    "        remove_outliers_dbscan(tmp_folder_path, 0.5, 10)\n",
    "    else:\n",
    "        remove_outliers_dbscan(emotion_folder_path, dbscan_eps, dbscan_min_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of the outliers per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "Label -1: 44 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_24139016_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_27212219_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_33469617_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_51610150_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_66705645_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_66705645_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_67702983_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PrivateTest_68333170_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\PublicTest_48413488_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_17526342_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_19726930_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_25131560_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_3074482_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_3279666_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_35803006_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_3598867_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_37911499_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_40192268_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_5300834_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_56096400_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_5630225_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_5645946_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_5645946_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_57549098_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61077408_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_61773462_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_63604344_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_65978744_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_6644670_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_67604214_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_71571159_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_7206687_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_72188974_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_73598349_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_87875595_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_94196223_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_95575116_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_96216570_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\angry\\Training_99588209_aug_5.jpg\n",
      "disgust\n",
      "Label -1: 47 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PrivateTest_34013087_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PrivateTest_53414692_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PrivateTest_76656607_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PrivateTest_98799539_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PublicTest_11387162_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PublicTest_41633403_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PublicTest_89570683_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\PublicTest_98815442_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_1070239_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_12026955_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_14719775_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_15104479_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_17705855_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_30792119_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_31108028_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_31108028_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_31573701_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_36703585_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_41001987_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_41238958_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_44470373_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_44993228_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_5258769_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_55559187_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_57692374_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_59161460_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_59409463_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_61291772_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_61342142_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_62239274_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_62239274_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_62239274_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_62886279_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_63147438_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_63156802_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_65759222_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_67030775_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_71118638_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_71679475_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_73889032_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_75609687_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_79212194_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_82237730_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_85767348_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_93689671_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_96754089_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\disgust\\Training_9948239_aug_5.jpg\n",
      "fear\n",
      "Label -1: 65 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_10306709_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_26581691_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_28273224_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_36996738_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_36996738_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_36996738_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PrivateTest_89129667_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PublicTest_15468267_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\PublicTest_54848341_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_1018372_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_10942406_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_13181629_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_18899448_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_2161263_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_21644135_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_24058572_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_25561886_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_26823187_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_30471858_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_31107495_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_32346910_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_32735149_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_33075662_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_33131991_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_34578336_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35100459_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_35633778_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_38188558_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_45169609_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_45488765_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_46366812_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_50362368_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_54053151_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_61960556_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_62764355_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_630805_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_67109543_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_72328939_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_73966221_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_75260133_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_75993265_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_81410671_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_81474503_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_81525924_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_81755794_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_84303199_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_87394233_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_8752857_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_9014912_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_93325481_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_93583767_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_93766134_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_9428052_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_95161986_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\fear\\Training_98882902_aug_6.jpg\n",
      "happy\n",
      "Label -1: 47 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PrivateTest_35915421_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PrivateTest_5142883_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_21832858_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_40705304_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_81760346_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_8909872_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\PublicTest_89636551_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_11546938_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_13969968_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_19307133_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_26537121_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_29662843_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_33313497_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_35439889_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_3720083_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_39657861_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_3984085_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_40433185_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_51289797_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_62100199_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_62231267_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_65883318_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_66991991_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_79076701_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_86210783_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_87607167_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_88157591_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_9961393_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\happy\\Training_99906271_aug_5.jpg\n",
      "neutral\n",
      "Label -1: 55 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PrivateTest_57076415_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PrivateTest_57076415_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PrivateTest_69339694_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PrivateTest_9130658_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_22397103_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_69096583_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_85599431_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_85967214_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_86444127_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_98333211_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_98333211_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_98333211_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\PublicTest_98333211_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_15913635_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_17843961_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_20906549_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_21438500_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_23468066_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_24022585_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_2445425_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_31414356_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_3542668_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_36986471_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_37024304_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_38562405_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_42279539_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_51124890_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_5177012_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_54750821_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_55091472_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_6110388_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_63359167_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_63754753_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_66880865_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_75186221_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_7749247_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_78787380_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_85413312_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_89335926_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_92030023_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_92347458_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_96958424_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_97267200_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\neutral\\Training_98951914_aug_1.jpg\n",
      "sad\n",
      "Label -1: 51 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_13548922_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_22791863_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_43570474_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_51713257_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_63060469_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_70717012_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PrivateTest_82792706_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PublicTest_19663674_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PublicTest_83014731_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\PublicTest_97750311_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_11036409_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_11175351_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_12165608_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_20336575_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_22912966_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25721710_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25949094_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25949094_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25949094_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25949094_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_25949094_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_35332527_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_35332527_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_35332527_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_35332527_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_48621797_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_50699732_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_594426_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_63208278_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_6436858_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_65552938_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_66106251_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_67842276_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_68289103_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_76656854_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_77117966_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_7816570_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_8214295_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_87857337_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_87857337_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_87857337_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_87857337_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_87857337_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_91805461_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\sad\\Training_96421728_aug_5.jpg\n",
      "surprise\n",
      "Label -1: 41 outliers\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_21197746_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_23514058_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_33008622_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_35458201_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_49077480_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_66164599_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_73154398_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PrivateTest_97163676_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PublicTest_39373170_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PublicTest_78591767_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PublicTest_80135522_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\PublicTest_83394959_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_10264146_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_12232006_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_27672614_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_27672614_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_29567186_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_42143192_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_42143192_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_0.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_2.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_3.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_4.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_48403842_aug_6.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_49076622_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_50140086_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_57669898_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_6966074_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_72825602_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_73838593_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_75067608_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_76252560_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_79616853_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_79769703_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_84259888_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_86145739_aug_1.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_86145739_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_90167636_aug_5.jpg\n",
      "C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\\surprise\\Training_96572434_aug_5.jpg\n"
     ]
    }
   ],
   "source": [
    "def calculate_pixel_std(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return np.std(image)\n",
    "\n",
    "def get_outliers_dbscan(folder_path, eps, min_samples):\n",
    "    images = []\n",
    "    image_paths = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        pixel_std = calculate_pixel_std(image_path)\n",
    "        images.append([pixel_std])\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    # dbscan to identify outliers\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(images)\n",
    "\n",
    "    # collect outlier paths and count for each label\n",
    "    outlier_paths_by_label = {}\n",
    "    for label, image_path in zip(labels, image_paths):\n",
    "        if label == -1:\n",
    "            if label not in outlier_paths_by_label:\n",
    "                outlier_paths_by_label[label] = []\n",
    "            outlier_paths_by_label[label].append(image_path)\n",
    "\n",
    "    return outlier_paths_by_label\n",
    "\n",
    "# Configurazione DBSCAN\n",
    "dbscan_eps = 0.5  # Raggio di ricerca\n",
    "dbscan_min_samples = 10  # Numero minimo di campioni in un cluster\n",
    "\n",
    "emotions_folder_path = r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images\"\n",
    "\n",
    "for emotion in os.listdir(emotions_folder_path):\n",
    "    emotion_folder_path = os.path.join(emotions_folder_path, emotion)\n",
    "    print(emotion)\n",
    "\n",
    "    if emotion == 'disgust':\n",
    "        tmp_folder_path = emotion_folder_path \n",
    "        outliers = get_outliers_dbscan(tmp_folder_path, 0.5, 10)\n",
    "    else:\n",
    "        outliers = get_outliers_dbscan(emotion_folder_path, dbscan_eps, dbscan_min_samples)\n",
    "\n",
    "    # Stampa i percorsi degli outliers per ogni label\n",
    "    for label, outlier_paths in outliers.items():\n",
    "        print(f\"Label {label}: {len(outlier_paths)} outliers\")\n",
    "        for path in outlier_paths:\n",
    "            print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**with over and under sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-** Using this method, a random selection of number_instances_over_under_sampling instances is made for each class. ########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation definition\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images'\n",
    "\n",
    "# create an instance of ImageFolder with the transformations\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# seed = 42\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# extract the labels and the indices of the dataset\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "\n",
    "# convert the list into a tensor\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# calculate the number of instances for each class\n",
    "counts = torch.bincount(labels)\n",
    "\n",
    "# calculate the weights for each class\n",
    "weights = 1.0 / counts.float()\n",
    "\n",
    "# create a weight vector for each index in the dataset\n",
    "sample_weights = weights[labels]\n",
    "\n",
    "# set the number of samples for the train set and the test set\n",
    "train_size = number_instances_over_under_sampling_ * 7 * 0.8\n",
    "val_size = number_instances_over_under_sampling_ * 7 * 0.1\n",
    "test_size = number_instances_over_under_sampling_ * 7 * 0.1\n",
    "\n",
    "# crea un sampler per il train set and one for the test set\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(train_size))\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(val_size))\n",
    "test_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(test_size))\n",
    "\n",
    "# create a dataloader for the train set and the test set with the corresponding samplers\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size_, sampler=train_sampler, num_workers=4)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size_, sampler=val_sampler, num_workers=4)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size_, sampler=test_sampler, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verifying if for each label there are number_instances_over_under_sampling instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances for class in the train set: tensor([24215, 23930, 23907, 23856, 23931, 23907, 24254])\n",
      "number of instances for class in the validation set: tensor([3052, 3019, 3029, 3027, 2921, 3047, 2905])\n",
      "number of instances for class in the test set: tensor([2935, 2953, 2998, 3093, 3000, 2991, 3030])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_10400\\4043918051.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_counts = torch.bincount(torch.tensor(labels)[train_indices])\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_10400\\4043918051.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_counts = torch.bincount(torch.tensor(labels)[val_indices])\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_10400\\4043918051.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_counts = torch.bincount(torch.tensor(labels)[test_indices])\n"
     ]
    }
   ],
   "source": [
    "train_indices = list(train_loader.sampler)\n",
    "train_counts = torch.bincount(torch.tensor(labels)[train_indices])\n",
    "print(\"number of instances for class in the train set:\", train_counts)\n",
    "\n",
    "val_indices = list(val_loader.sampler)\n",
    "val_counts = torch.bincount(torch.tensor(labels)[val_indices])\n",
    "print(\"number of instances for class in the validation set:\", val_counts)\n",
    "\n",
    "test_indices = list(test_loader.sampler)\n",
    "test_counts = torch.bincount(torch.tensor(labels)[test_indices])\n",
    "print(\"number of instances for class in the test set:\", test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 438, 438)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning these are the number of instances for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class angry: 34671 istances\n",
      "Class disgust: 3829 istances\n",
      "Class fear: 35847 istances\n",
      "Class happy: 62923 istances\n",
      "Class neutral: 43386 istances\n",
      "Class sad: 42539 istances\n",
      "Class surprise: 28014 istances\n"
     ]
    }
   ],
   "source": [
    "# obtain the classes (labels)\n",
    "classes = dataset.classes\n",
    "\n",
    "# count the instances for each class\n",
    "instances_per_class = {cls: 0 for cls in classes}\n",
    "\n",
    "for _, label in dataset.imgs:\n",
    "    instances_per_class[classes[label]] += 1\n",
    "\n",
    "# print(\"Number of instances per class:\")\n",
    "for cls, count in instances_per_class.items():\n",
    "    print(f\"Class {cls}: {count} istances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => Train Loss: 1.9459, Train Accuracy: 0.1480\n",
      "Angry: Train Precision: 0.1479, Train Recall: 0.1217, Train F1: 0.1336, Train Support: 16033\n",
      "Disgust: Train Precision: 0.1392, Train Recall: 0.1083, Train F1: 0.1218, Train Support: 16049\n",
      "Fear: Train Precision: 0.1250, Train Recall: 0.0001, Train F1: 0.0001, Train Support: 15950\n",
      "Happy: Train Precision: 0.1438, Train Recall: 0.2303, Train F1: 0.1770, Train Support: 16080\n",
      "Neutral: Train Precision: 0.1478, Train Recall: 0.0707, Train F1: 0.0956, Train Support: 15890\n",
      "Sad: Train Precision: 0.1440, Train Recall: 0.2054, Train F1: 0.1693, Train Support: 15916\n",
      "Surprise: Train Precision: 0.1584, Train Recall: 0.2980, Train F1: 0.2069, Train Support: 16082\n",
      "Validation Loss: 1.9457, Validation Accuracy: 0.1679\n",
      "Angry: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 1941\n",
      "Disgust: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 1989\n",
      "Fear: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 2015\n",
      "Happy: Validation Precision: 0.1479, Validation Recall: 0.6445, Validation F1: 0.2406, Validation Support: 2076\n",
      "Neutral: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 1944\n",
      "Sad: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 2038\n",
      "Surprise: Validation Precision: 0.2044, Validation Recall: 0.5073, Validation F1: 0.2914, Validation Support: 1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\project-venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 => Train Loss: 1.9389, Train Accuracy: 0.1712\n",
      "Angry: Train Precision: 0.1532, Train Recall: 0.4038, Train F1: 0.2221, Train Support: 16162\n",
      "Disgust: Train Precision: 0.1734, Train Recall: 0.0051, Train F1: 0.0099, Train Support: 15956\n",
      "Fear: Train Precision: 0.0727, Train Recall: 0.0002, Train F1: 0.0005, Train Support: 16023\n",
      "Happy: Train Precision: 0.1430, Train Recall: 0.0943, Train F1: 0.1137, Train Support: 15971\n",
      "Neutral: Train Precision: 0.1745, Train Recall: 0.0593, Train F1: 0.0885, Train Support: 16008\n",
      "Sad: Train Precision: 0.1734, Train Recall: 0.2551, Train F1: 0.2065, Train Support: 16047\n",
      "Surprise: Train Precision: 0.2052, Train Recall: 0.3798, Train F1: 0.2664, Train Support: 15833\n",
      "Validation Loss: 1.9242, Validation Accuracy: 0.1991\n",
      "Angry: Validation Precision: 0.2056, Validation Recall: 0.1438, Validation F1: 0.1692, Validation Support: 1989\n",
      "Disgust: Validation Precision: 0.1846, Validation Recall: 0.0061, Validation F1: 0.0118, Validation Support: 1971\n",
      "Fear: Validation Precision: 0.0000, Validation Recall: 0.0000, Validation F1: 0.0000, Validation Support: 1946\n",
      "Happy: Validation Precision: 0.2261, Validation Recall: 0.0776, Validation F1: 0.1156, Validation Support: 2010\n",
      "Neutral: Validation Precision: 0.2345, Validation Recall: 0.0567, Validation F1: 0.0913, Validation Support: 2063\n",
      "Sad: Validation Precision: 0.1925, Validation Recall: 0.3729, Validation F1: 0.2539, Validation Support: 2006\n",
      "Surprise: Validation Precision: 0.1965, Validation Recall: 0.7285, Validation F1: 0.3095, Validation Support: 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 => Train Loss: 1.9033, Train Accuracy: 0.2240\n",
      "Angry: Train Precision: 0.1939, Train Recall: 0.2202, Train F1: 0.2063, Train Support: 15932\n",
      "Disgust: Train Precision: 0.2226, Train Recall: 0.1919, Train F1: 0.2061, Train Support: 16082\n",
      "Fear: Train Precision: 0.1583, Train Recall: 0.0130, Train F1: 0.0240, Train Support: 16011\n",
      "Happy: Train Precision: 0.2174, Train Recall: 0.2830, Train F1: 0.2459, Train Support: 16002\n",
      "Neutral: Train Precision: 0.1823, Train Recall: 0.1238, Train F1: 0.1474, Train Support: 15878\n",
      "Sad: Train Precision: 0.1909, Train Recall: 0.2283, Train F1: 0.2079, Train Support: 16082\n",
      "Surprise: Train Precision: 0.2913, Train Recall: 0.5071, Train F1: 0.3700, Train Support: 16013\n",
      "Validation Loss: 1.8859, Validation Accuracy: 0.2509\n",
      "Angry: Validation Precision: 0.2387, Validation Recall: 0.1595, Validation F1: 0.1912, Validation Support: 2050\n",
      "Disgust: Validation Precision: 0.2477, Validation Recall: 0.3495, Validation F1: 0.2899, Validation Support: 1960\n",
      "Fear: Validation Precision: 0.1713, Validation Recall: 0.0519, Validation F1: 0.0797, Validation Support: 2002\n",
      "Happy: Validation Precision: 0.2435, Validation Recall: 0.4673, Validation F1: 0.3201, Validation Support: 1990\n",
      "Neutral: Validation Precision: 0.2116, Validation Recall: 0.0254, Validation F1: 0.0454, Validation Support: 2004\n",
      "Sad: Validation Precision: 0.1940, Validation Recall: 0.3390, Validation F1: 0.2468, Validation Support: 1991\n",
      "Surprise: Validation Precision: 0.4312, Validation Recall: 0.3694, Validation F1: 0.3980, Validation Support: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 => Train Loss: 1.8649, Train Accuracy: 0.2731\n",
      "Angry: Train Precision: 0.2171, Train Recall: 0.2066, Train F1: 0.2117, Train Support: 16030\n",
      "Disgust: Train Precision: 0.2902, Train Recall: 0.3569, Train F1: 0.3201, Train Support: 15898\n",
      "Fear: Train Precision: 0.1843, Train Recall: 0.0919, Train F1: 0.1226, Train Support: 16171\n",
      "Happy: Train Precision: 0.2832, Train Recall: 0.4807, Train F1: 0.3564, Train Support: 16059\n",
      "Neutral: Train Precision: 0.1847, Train Recall: 0.0584, Train F1: 0.0888, Train Support: 15854\n",
      "Sad: Train Precision: 0.2078, Train Recall: 0.2256, Train F1: 0.2164, Train Support: 16002\n",
      "Surprise: Train Precision: 0.4030, Train Recall: 0.4914, Train F1: 0.4428, Train Support: 15986\n",
      "Validation Loss: 1.8457, Validation Accuracy: 0.2966\n",
      "Angry: Validation Precision: 0.2582, Validation Recall: 0.1829, Validation F1: 0.2142, Validation Support: 1968\n",
      "Disgust: Validation Precision: 0.3941, Validation Recall: 0.2639, Validation F1: 0.3161, Validation Support: 2008\n",
      "Fear: Validation Precision: 0.1762, Validation Recall: 0.0843, Validation F1: 0.1141, Validation Support: 2016\n",
      "Happy: Validation Precision: 0.2898, Validation Recall: 0.5648, Validation F1: 0.3830, Validation Support: 1999\n",
      "Neutral: Validation Precision: 0.2334, Validation Recall: 0.0773, Validation F1: 0.1161, Validation Support: 2044\n",
      "Sad: Validation Precision: 0.2386, Validation Recall: 0.3400, Validation F1: 0.2804, Validation Support: 1962\n",
      "Surprise: Validation Precision: 0.3888, Validation Recall: 0.5681, Validation F1: 0.4617, Validation Support: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 => Train Loss: 1.8276, Train Accuracy: 0.3166\n",
      "Angry: Train Precision: 0.2363, Train Recall: 0.1839, Train F1: 0.2068, Train Support: 16093\n",
      "Disgust: Train Precision: 0.3650, Train Recall: 0.4224, Train F1: 0.3916, Train Support: 15887\n",
      "Fear: Train Precision: 0.1984, Train Recall: 0.0868, Train F1: 0.1207, Train Support: 15965\n",
      "Happy: Train Precision: 0.3630, Train Recall: 0.4960, Train F1: 0.4192, Train Support: 15943\n",
      "Neutral: Train Precision: 0.2414, Train Recall: 0.1730, Train F1: 0.2015, Train Support: 15907\n",
      "Sad: Train Precision: 0.2404, Train Recall: 0.2934, Train F1: 0.2643, Train Support: 16196\n",
      "Surprise: Train Precision: 0.4251, Train Recall: 0.5620, Train F1: 0.4841, Train Support: 16009\n",
      "Validation Loss: 1.8078, Validation Accuracy: 0.3407\n",
      "Angry: Validation Precision: 0.2563, Validation Recall: 0.1929, Validation F1: 0.2201, Validation Support: 1991\n",
      "Disgust: Validation Precision: 0.3470, Validation Recall: 0.5716, Validation F1: 0.4318, Validation Support: 2003\n",
      "Fear: Validation Precision: 0.2319, Validation Recall: 0.2191, Validation F1: 0.2253, Validation Support: 1990\n",
      "Happy: Validation Precision: 0.3332, Validation Recall: 0.5965, Validation F1: 0.4276, Validation Support: 2015\n",
      "Neutral: Validation Precision: 0.3442, Validation Recall: 0.0912, Validation F1: 0.1442, Validation Support: 2083\n",
      "Sad: Validation Precision: 0.3128, Validation Recall: 0.1741, Validation F1: 0.2237, Validation Support: 1930\n",
      "Surprise: Validation Precision: 0.5156, Validation Recall: 0.5418, Validation F1: 0.5283, Validation Support: 1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 => Train Loss: 1.7911, Train Accuracy: 0.3580\n",
      "Angry: Train Precision: 0.2731, Train Recall: 0.2015, Train F1: 0.2319, Train Support: 15838\n",
      "Disgust: Train Precision: 0.4436, Train Recall: 0.4749, Train F1: 0.4587, Train Support: 16108\n",
      "Fear: Train Precision: 0.2222, Train Recall: 0.0925, Train F1: 0.1306, Train Support: 15954\n",
      "Happy: Train Precision: 0.4011, Train Recall: 0.5477, Train F1: 0.4631, Train Support: 15988\n",
      "Neutral: Train Precision: 0.2815, Train Recall: 0.2811, Train F1: 0.2813, Train Support: 15918\n",
      "Sad: Train Precision: 0.2630, Train Recall: 0.2840, Train F1: 0.2731, Train Support: 16011\n",
      "Surprise: Train Precision: 0.4671, Train Recall: 0.6181, Train F1: 0.5321, Train Support: 16183\n",
      "Validation Loss: 1.7813, Validation Accuracy: 0.3708\n",
      "Angry: Validation Precision: 0.2717, Validation Recall: 0.3434, Validation F1: 0.3034, Validation Support: 1989\n",
      "Disgust: Validation Precision: 0.5825, Validation Recall: 0.4239, Validation F1: 0.4907, Validation Support: 2024\n",
      "Fear: Validation Precision: 0.2757, Validation Recall: 0.0622, Validation F1: 0.1015, Validation Support: 2025\n",
      "Happy: Validation Precision: 0.3704, Validation Recall: 0.6663, Validation F1: 0.4762, Validation Support: 1978\n",
      "Neutral: Validation Precision: 0.4110, Validation Recall: 0.1693, Validation F1: 0.2398, Validation Support: 1979\n",
      "Sad: Validation Precision: 0.3470, Validation Recall: 0.1672, Validation F1: 0.2257, Validation Support: 2027\n",
      "Surprise: Validation Precision: 0.3642, Validation Recall: 0.7745, Validation F1: 0.4955, Validation Support: 1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 => Train Loss: 1.7614, Train Accuracy: 0.3901\n",
      "Angry: Train Precision: 0.2936, Train Recall: 0.2518, Train F1: 0.2711, Train Support: 15955\n",
      "Disgust: Train Precision: 0.4969, Train Recall: 0.5199, Train F1: 0.5082, Train Support: 15868\n",
      "Fear: Train Precision: 0.2481, Train Recall: 0.1061, Train F1: 0.1486, Train Support: 16195\n",
      "Happy: Train Precision: 0.4458, Train Recall: 0.5745, Train F1: 0.5021, Train Support: 15923\n",
      "Neutral: Train Precision: 0.3278, Train Recall: 0.3641, Train F1: 0.3450, Train Support: 16264\n",
      "Sad: Train Precision: 0.2787, Train Recall: 0.2803, Train F1: 0.2795, Train Support: 16045\n",
      "Surprise: Train Precision: 0.5052, Train Recall: 0.6439, Train F1: 0.5662, Train Support: 15750\n",
      "Validation Loss: 1.7432, Validation Accuracy: 0.4108\n",
      "Angry: Validation Precision: 0.2973, Validation Recall: 0.3183, Validation F1: 0.3074, Validation Support: 1989\n",
      "Disgust: Validation Precision: 0.5329, Validation Recall: 0.5937, Validation F1: 0.5617, Validation Support: 1979\n",
      "Fear: Validation Precision: 0.2760, Validation Recall: 0.1174, Validation F1: 0.1647, Validation Support: 2011\n",
      "Happy: Validation Precision: 0.4127, Validation Recall: 0.6536, Validation F1: 0.5059, Validation Support: 2021\n",
      "Neutral: Validation Precision: 0.4137, Validation Recall: 0.2904, Validation F1: 0.3412, Validation Support: 2032\n",
      "Sad: Validation Precision: 0.2821, Validation Recall: 0.3393, Validation F1: 0.3081, Validation Support: 1966\n",
      "Surprise: Validation Precision: 0.6203, Validation Recall: 0.5639, Validation F1: 0.5908, Validation Support: 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 => Train Loss: 1.7350, Train Accuracy: 0.4187\n",
      "Angry: Train Precision: 0.3278, Train Recall: 0.2919, Train F1: 0.3088, Train Support: 16047\n",
      "Disgust: Train Precision: 0.5426, Train Recall: 0.5397, Train F1: 0.5411, Train Support: 16065\n",
      "Fear: Train Precision: 0.2800, Train Recall: 0.1208, Train F1: 0.1687, Train Support: 16140\n",
      "Happy: Train Precision: 0.4862, Train Recall: 0.5953, Train F1: 0.5352, Train Support: 15941\n",
      "Neutral: Train Precision: 0.3491, Train Recall: 0.4015, Train F1: 0.3735, Train Support: 15802\n",
      "Sad: Train Precision: 0.3016, Train Recall: 0.3196, Train F1: 0.3103, Train Support: 16132\n",
      "Surprise: Train Precision: 0.5307, Train Recall: 0.6682, Train F1: 0.5916, Train Support: 15873\n",
      "Validation Loss: 1.7246, Validation Accuracy: 0.4286\n",
      "Angry: Validation Precision: 0.3365, Validation Recall: 0.3261, Validation F1: 0.3312, Validation Support: 2064\n",
      "Disgust: Validation Precision: 0.4939, Validation Recall: 0.6162, Validation F1: 0.5483, Validation Support: 1907\n",
      "Fear: Validation Precision: 0.3320, Validation Recall: 0.0821, Validation F1: 0.1316, Validation Support: 2010\n",
      "Happy: Validation Precision: 0.4589, Validation Recall: 0.6227, Validation F1: 0.5284, Validation Support: 2001\n",
      "Neutral: Validation Precision: 0.3388, Validation Recall: 0.4960, Validation F1: 0.4026, Validation Support: 1982\n",
      "Sad: Validation Precision: 0.4100, Validation Recall: 0.1394, Validation F1: 0.2080, Validation Support: 2059\n",
      "Surprise: Validation Precision: 0.5239, Validation Recall: 0.7441, Validation F1: 0.6148, Validation Support: 1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 => Train Loss: 1.7079, Train Accuracy: 0.4480\n",
      "Angry: Train Precision: 0.3625, Train Recall: 0.3296, Train F1: 0.3453, Train Support: 16082\n",
      "Disgust: Train Precision: 0.5960, Train Recall: 0.5735, Train F1: 0.5845, Train Support: 15968\n",
      "Fear: Train Precision: 0.2918, Train Recall: 0.1423, Train F1: 0.1913, Train Support: 16005\n",
      "Happy: Train Precision: 0.5205, Train Recall: 0.6281, Train F1: 0.5692, Train Support: 16039\n",
      "Neutral: Train Precision: 0.3743, Train Recall: 0.4378, Train F1: 0.4035, Train Support: 16020\n",
      "Sad: Train Precision: 0.3209, Train Recall: 0.3293, Train F1: 0.3251, Train Support: 15972\n",
      "Surprise: Train Precision: 0.5622, Train Recall: 0.6968, Train F1: 0.6223, Train Support: 15914\n",
      "Validation Loss: 1.6891, Validation Accuracy: 0.4684\n",
      "Angry: Validation Precision: 0.3504, Validation Recall: 0.4328, Validation F1: 0.3872, Validation Support: 1948\n",
      "Disgust: Validation Precision: 0.6357, Validation Recall: 0.5891, Validation F1: 0.6115, Validation Support: 2020\n",
      "Fear: Validation Precision: 0.3816, Validation Recall: 0.0533, Validation F1: 0.0935, Validation Support: 2027\n",
      "Happy: Validation Precision: 0.5387, Validation Recall: 0.6576, Validation F1: 0.5922, Validation Support: 2033\n",
      "Neutral: Validation Precision: 0.4309, Validation Recall: 0.4066, Validation F1: 0.4184, Validation Support: 1980\n",
      "Sad: Validation Precision: 0.3088, Validation Recall: 0.4601, Validation F1: 0.3695, Validation Support: 2004\n",
      "Surprise: Validation Precision: 0.6429, Validation Recall: 0.6801, Validation F1: 0.6610, Validation Support: 1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 => Train Loss: 1.6869, Train Accuracy: 0.4691\n",
      "Angry: Train Precision: 0.3784, Train Recall: 0.3699, Train F1: 0.3741, Train Support: 16027\n",
      "Disgust: Train Precision: 0.6422, Train Recall: 0.5979, Train F1: 0.6193, Train Support: 16085\n",
      "Fear: Train Precision: 0.3303, Train Recall: 0.1574, Train F1: 0.2132, Train Support: 16005\n",
      "Happy: Train Precision: 0.5504, Train Recall: 0.6310, Train F1: 0.5879, Train Support: 16001\n",
      "Neutral: Train Precision: 0.3900, Train Recall: 0.4649, Train F1: 0.4242, Train Support: 16036\n",
      "Sad: Train Precision: 0.3351, Train Recall: 0.3547, Train F1: 0.3446, Train Support: 15854\n",
      "Surprise: Train Precision: 0.5795, Train Recall: 0.7062, Train F1: 0.6366, Train Support: 15992\n",
      "Validation Loss: 1.6660, Validation Accuracy: 0.4919\n",
      "Angry: Validation Precision: 0.3778, Validation Recall: 0.4078, Validation F1: 0.3922, Validation Support: 2001\n",
      "Disgust: Validation Precision: 0.7236, Validation Recall: 0.6090, Validation F1: 0.6613, Validation Support: 2033\n",
      "Fear: Validation Precision: 0.3595, Validation Recall: 0.2067, Validation F1: 0.2625, Validation Support: 1974\n",
      "Happy: Validation Precision: 0.6362, Validation Recall: 0.5762, Validation F1: 0.6047, Validation Support: 2027\n",
      "Neutral: Validation Precision: 0.3789, Validation Recall: 0.5697, Validation F1: 0.4551, Validation Support: 1980\n",
      "Sad: Validation Precision: 0.4222, Validation Recall: 0.2639, Validation F1: 0.3248, Validation Support: 2035\n",
      "Surprise: Validation Precision: 0.5473, Validation Recall: 0.8164, Validation F1: 0.6553, Validation Support: 1950\n",
      "Best model achieved at epoch 10 with accuracy 0.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# definition of the model, criterion, optimizer and scheduler\n",
    "net = EmotionCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=5, verbose=True)\n",
    "\n",
    "def calculate_metrics_per_class(true_labels, predicted_labels, label_mapping):\n",
    "    unique_labels = list(label_mapping.keys())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(true_labels, predicted_labels, labels=unique_labels)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    metrics_per_class = {}\n",
    "    for i, idx in enumerate(unique_labels):\n",
    "        metrics_per_class[idx] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    return accuracy, metrics_per_class\n",
    "\n",
    "# function for training\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, label_mapping):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc='Training', leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    accuracy, metrics_per_class = calculate_metrics_per_class(true_labels, predicted_labels, label_mapping)\n",
    "\n",
    "    return average_loss, accuracy, metrics_per_class\n",
    "\n",
    "# function for evaluation\n",
    "def evaluate(model, val_loader, criterion, device, label_mapping):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Validation', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    average_loss = running_loss / len(val_loader)\n",
    "    accuracy, metrics_per_class = calculate_metrics_per_class(true_labels, predicted_labels, label_mapping)\n",
    "\n",
    "    return average_loss, accuracy, metrics_per_class\n",
    "\n",
    "# Settings\n",
    "num_epochs = epochs_\n",
    "early_stopping_patience = 3  # numbers of epochs with no improvement after which training will be stopped (early stopping)\n",
    "best_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "no_improvement_count = 0\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss, train_accuracy, train_metrics_per_class = train_epoch(net, train_loader, criterion, optimizer, device, your_label_mapping)\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_accuracy, val_metrics_per_class = evaluate(net, val_loader, criterion, device, your_label_mapping)\n",
    "\n",
    "    # Scheduler step based on validation accuracy\n",
    "    scheduler.step(val_accuracy)\n",
    "\n",
    "    # Saving the model if the current accuracy is better than the best\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        torch.save(net.state_dict(), r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\paper1_models\\best_model.pth')\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} => '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Print metrics per class\n",
    "    for idx, label in your_label_mapping.items():\n",
    "        print(f'{label}: Train Precision: {train_metrics_per_class[idx][\"precision\"]:.4f}, Train Recall: {train_metrics_per_class[idx][\"recall\"]:.4f}, Train F1: {train_metrics_per_class[idx][\"f1\"]:.4f}, Train Support: {train_metrics_per_class[idx][\"support\"]}')\n",
    "\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    for idx, label in your_label_mapping.items():\n",
    "        print(f'{label}: Validation Precision: {val_metrics_per_class[idx][\"precision\"]:.4f}, Validation Recall: {val_metrics_per_class[idx][\"recall\"]:.4f}, Validation F1: {val_metrics_per_class[idx][\"f1\"]:.4f}, Validation Support: {val_metrics_per_class[idx][\"support\"]}')\n",
    "\n",
    "    if no_improvement_count >= early_stopping_patience:\n",
    "        print(f'Early stopping at epoch {epoch + 1} as there is no improvement in validation accuracy for {early_stopping_patience} consecutive epochs.')\n",
    "        break\n",
    "\n",
    "print(f'Best model achieved at epoch {best_epoch + 1} with accuracy {best_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5174, Test Accuracy: 0.6449\n",
      "Angry: Test Precision: 0.6377, Test Recall: 0.5531, Test F1: 0.5924, Test Support: 2985\n",
      "Disgust: Test Precision: 0.8761, Test Recall: 0.8458, Test F1: 0.8607, Test Support: 3035\n",
      "Fear: Test Precision: 0.6128, Test Recall: 0.3440, Test F1: 0.4407, Test Support: 2968\n",
      "Happy: Test Precision: 0.7352, Test Recall: 0.7319, Test F1: 0.7335, Test Support: 3133\n",
      "Neutral: Test Precision: 0.5036, Test Recall: 0.6099, Test F1: 0.5517, Test Support: 2848\n",
      "Sad: Test Precision: 0.5069, Test Recall: 0.5822, Test F1: 0.5419, Test Support: 3040\n",
      "Surprise: Test Precision: 0.6668, Test Recall: 0.8372, Test F1: 0.7424, Test Support: 2991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_per_class(true_labels, predicted_labels, label_mapping):\n",
    "    unique_labels = list(label_mapping.keys())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(true_labels, predicted_labels, labels=unique_labels)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    metrics_per_class = {}\n",
    "    for i, idx in enumerate(unique_labels):\n",
    "        metrics_per_class[idx] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    return accuracy, metrics_per_class\n",
    "\n",
    "# Funzione per il test\n",
    "def test(model, test_loader, criterion, device, label_mapping):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    average_loss = running_loss / len(test_loader)\n",
    "    accuracy, metrics_per_class = calculate_metrics_per_class(true_labels, predicted_labels, label_mapping)\n",
    "\n",
    "    return average_loss, accuracy, metrics_per_class\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carica il modello con i pesi migliori\n",
    "best_model = EmotionCNN()\n",
    "best_model.load_state_dict(torch.load(r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\paper1_models\\best_model_paper_1_20_epochs.pth', map_location=torch.device('cpu')))\n",
    "best_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "\n",
    "\n",
    "# Test\n",
    "test_loss, test_accuracy, test_metrics_per_class = test(best_model, test_loader, criterion, device, your_label_mapping)\n",
    "\n",
    "# Print metrics per class per il test set\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "for idx, label in your_label_mapping.items():\n",
    "    print(f'{label}: Test Precision: {test_metrics_per_class[idx][\"precision\"]:.4f}, Test Recall: {test_metrics_per_class[idx][\"recall\"]:.4f}, Test F1: {test_metrics_per_class[idx][\"f1\"]:.4f}, Test Support: {test_metrics_per_class[idx][\"support\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation definition\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\test_images_emotion'\n",
    "\n",
    "# create an instance of ImageFolder with the transformations\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# seed = 42\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# extract the labels and the indices of the dataset\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "\n",
    "# convert the list into a tensor\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# calculate the number of instances for each class\n",
    "counts = torch.bincount(labels)\n",
    "\n",
    "# calculate the weights for each class\n",
    "weights = 1.0 / counts.float()\n",
    "\n",
    "# create a weight vector for each index in the dataset\n",
    "sample_weights = weights[labels]\n",
    "\n",
    "# set the number of samples for the train set and the test set\n",
    "train_size = (number_instances_over_under_sampling_/10) * 7 * 0.1\n",
    "val_size = (number_instances_over_under_sampling_/10) * 7 * 0.1\n",
    "test_size = (number_instances_over_under_sampling_/10) * 7 * 0.8\n",
    "\n",
    "# crea un sampler per il train set and one for the test set\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(train_size))\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(val_size))\n",
    "test_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(test_size))\n",
    "\n",
    "# create a dataloader for the train set and the test set with the corresponding samplers\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size_, sampler=train_sampler, num_workers=4)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size_, sampler=val_sampler, num_workers=4)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size_, sampler=test_sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7224, Test Accuracy: 0.4370\n",
      "Angry: Test Precision: 0.4473, Test Recall: 0.4866, Test F1: 0.4661, Test Support: 2396\n",
      "Disgust: Test Precision: 0.5868, Test Recall: 0.1765, Test F1: 0.2714, Test Support: 2413\n",
      "Fear: Test Precision: 0.4612, Test Recall: 0.2049, Test F1: 0.2838, Test Support: 2435\n",
      "Happy: Test Precision: 0.4209, Test Recall: 0.9003, Test F1: 0.5736, Test Support: 2396\n",
      "Neutral: Test Precision: 0.3623, Test Recall: 0.5517, Test F1: 0.4373, Test Support: 2369\n",
      "Sad: Test Precision: 0.3717, Test Recall: 0.2944, Test F1: 0.3286, Test Support: 2357\n",
      "Surprise: Test Precision: 0.6118, Test Recall: 0.4486, Test F1: 0.5177, Test Support: 2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_per_class(true_labels, predicted_labels, label_mapping):\n",
    "    unique_labels = list(label_mapping.keys())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(true_labels, predicted_labels, labels=unique_labels)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    metrics_per_class = {}\n",
    "    for i, idx in enumerate(unique_labels):\n",
    "        metrics_per_class[idx] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    return accuracy, metrics_per_class\n",
    "\n",
    "# Funzione per il test\n",
    "def test(model, test_loader, criterion, device, label_mapping):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    average_loss = running_loss / len(test_loader)\n",
    "    accuracy, metrics_per_class = calculate_metrics_per_class(true_labels, predicted_labels, label_mapping)\n",
    "\n",
    "    return average_loss, accuracy, metrics_per_class\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carica il modello con i pesi migliori\n",
    "best_model = EmotionCNN()\n",
    "best_model.load_state_dict(torch.load(r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\paper1_models\\best_model_paper_1_20_epochs_bs_48_30k.pth', map_location=torch.device('cpu')))\n",
    "best_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "\n",
    "\n",
    "# Test\n",
    "test_loss, test_accuracy, test_metrics_per_class = test(best_model, test_loader, criterion, device, your_label_mapping)\n",
    "\n",
    "# Print metrics per class per il test set\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "for idx, label in your_label_mapping.items():\n",
    "    print(f'{label}: Test Precision: {test_metrics_per_class[idx][\"precision\"]:.4f}, Test Recall: {test_metrics_per_class[idx][\"recall\"]:.4f}, Test F1: {test_metrics_per_class[idx][\"f1\"]:.4f}, Test Support: {test_metrics_per_class[idx][\"support\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Live emotion detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "model = EmotionCNN(num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\paper1_models\\best_model_paper_1_20_epochs_bs_48_30k.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval() \n",
    "\n",
    "# initialize the face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# apply the transformations to the face image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "while True:\n",
    "    # read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # faces detection\n",
    "    faces = detector(frame)\n",
    "\n",
    "    # if there is at least one face detected, process the image\n",
    "    if len(faces) > 0:\n",
    "        # take only the first face\n",
    "        face = faces[0]\n",
    "        \n",
    "        # cut the face from the frame\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        face_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # check if the face image is not empty\n",
    "        if not face_image.size == 0:\n",
    "            # apply the transformations to the face image\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB))\n",
    "            input_image = transform(pil_image).unsqueeze(0)  # Aggiunge una dimensione di batch\n",
    "            input_image = input_image.to(device)\n",
    "\n",
    "            # model prediction\n",
    "            with torch.no_grad():\n",
    "                output = model(input_image)\n",
    "\n",
    "            # get the label predicted by the model\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_emotion = your_label_mapping[predicted.item()]\n",
    "\n",
    "            print(f'Predicted Emotion: {predicted_emotion}')\n",
    "\n",
    "    # show the frame with the face rectangle added\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    # wait for 2 seconds (time in milliseconds)\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "    # if q is pressed, terminate the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
