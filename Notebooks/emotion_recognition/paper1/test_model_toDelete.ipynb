{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from PIL import Image\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=2)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2a = nn.ReLU()\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2b = nn.ReLU()\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3a = nn.ReLU()\n",
    "        self.conv3b = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3b = nn.ReLU()\n",
    "        self.avgpool3 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        # verify the output size of conv2 and conv3\n",
    "        self.dummy_input = torch.randn(1, 1, 48, 48)\n",
    "        self.dummy_output_size = self._get_conv_output_size(self.dummy_input)\n",
    "        \n",
    "        # update fc1 units based on feature map size\n",
    "        self.fc1 = nn.Linear(self.dummy_output_size, 1024)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output_size(self, input_tensor):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(input_tensor)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.relu2a(self.conv2a(x))\n",
    "        x = self.relu2b(self.conv2b(x))\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.relu3a(self.conv3a(x))\n",
    "        x = self.relu3b(self.conv3b(x))\n",
    "        x = self.avgpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout1(self.relu_fc1(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu_fc2(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances_over_under_sampling_ = 20000\n",
    "batch_size_ = 48\n",
    "epochs_ = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation definition\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\emotions_aug_images'\n",
    "\n",
    "# create an instance of ImageFolder with the transformations\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# seed = 42\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# extract the labels and the indices of the dataset\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "\n",
    "# convert the list into a tensor\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# calculate the number of instances for each class\n",
    "counts = torch.bincount(labels)\n",
    "\n",
    "# calculate the weights for each class\n",
    "weights = 1.0 / counts.float()\n",
    "\n",
    "# create a weight vector for each index in the dataset\n",
    "sample_weights = weights[labels]\n",
    "\n",
    "# set the number of samples for the train set and the test set\n",
    "train_size = number_instances_over_under_sampling_ * 7 * 0.8\n",
    "val_size = number_instances_over_under_sampling_ * 7 * 0.1\n",
    "test_size = number_instances_over_under_sampling_ * 7 * 0.1\n",
    "\n",
    "# crea un sampler per il train set and one for the test set\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(train_size))\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(val_size))\n",
    "test_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(test_size))\n",
    "\n",
    "# create a dataloader for the train set and the test set with the corresponding samplers\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size_, sampler=train_sampler, num_workers=4)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size_, sampler=val_sampler, num_workers=4)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size_, sampler=test_sampler, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation definition\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset_root = r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Data\\test_images_emotion'\n",
    "\n",
    "# create an instance of ImageFolder with the transformations\n",
    "dataset = ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# seed = 42\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# extract the labels and the indices of the dataset\n",
    "labels = [label for _, label in dataset.imgs]\n",
    "\n",
    "# convert the list into a tensor\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# calculate the number of instances for each class\n",
    "counts = torch.bincount(labels)\n",
    "\n",
    "# calculate the weights for each class\n",
    "weights = 1.0 / counts.float()\n",
    "\n",
    "# create a weight vector for each index in the dataset\n",
    "sample_weights = weights[labels]\n",
    "\n",
    "# set the number of samples for the train set and the test set\n",
    "train_size = (number_instances_over_under_sampling_/10) * 7 * 0.1\n",
    "val_size = (number_instances_over_under_sampling_/10) * 7 * 0.1\n",
    "test_size = (number_instances_over_under_sampling_/10) * 7 * 0.8\n",
    "\n",
    "# crea un sampler per il train set and one for the test set\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(train_size))\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(val_size))\n",
    "test_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, int(test_size))\n",
    "\n",
    "# create a dataloader for the train set and the test set with the corresponding samplers\n",
    "train_loader_ = DataLoader(dataset, batch_size=batch_size_, sampler=train_sampler, num_workers=4)\n",
    "val_loader_ = DataLoader(dataset, batch_size=batch_size_, sampler=val_sampler, num_workers=4)\n",
    "test_loader_ = DataLoader(dataset, batch_size=batch_size_, sampler=test_sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4909, Test Accuracy: 0.6717\n",
      "Test Loss: 1.7281, Test Accuracy: 0.4297\n",
      "Angry: Test Precision: 0.6549, Test Recall: 0.5835, Test F1: 0.6171, Test Support: 2000\n",
      "Disgust: Test Precision: 0.9018, Test Recall: 0.8546, Test F1: 0.8776, Test Support: 1988\n",
      "Fear: Test Precision: 0.6561, Test Recall: 0.4019, Test F1: 0.4985, Test Support: 2003\n",
      "Happy: Test Precision: 0.7636, Test Recall: 0.7332, Test F1: 0.7481, Test Support: 2080\n",
      "Neutral: Test Precision: 0.5245, Test Recall: 0.6624, Test F1: 0.5855, Test Support: 1887\n",
      "Sad: Test Precision: 0.5437, Test Recall: 0.6002, Test F1: 0.5706, Test Support: 2011\n",
      "Surprise: Test Precision: 0.6984, Test Recall: 0.8621, Test F1: 0.7717, Test Support: 2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_per_class(true_labels, predicted_labels, label_mapping):\n",
    "    unique_labels = list(label_mapping.keys())\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(true_labels, predicted_labels, labels=unique_labels)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    metrics_per_class = {}\n",
    "    for i, idx in enumerate(unique_labels):\n",
    "        metrics_per_class[idx] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    return accuracy, metrics_per_class\n",
    "\n",
    "# Funzione per il test\n",
    "def test(model, test_loader, criterion, device, label_mapping):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    average_loss = running_loss / len(test_loader)\n",
    "    accuracy, metrics_per_class = calculate_metrics_per_class(true_labels, predicted_labels, label_mapping)\n",
    "\n",
    "    return average_loss, accuracy, metrics_per_class\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carica il modello con i pesi migliori\n",
    "best_model = EmotionCNN()\n",
    "best_model.load_state_dict(torch.load(r'C:\\Users\\marco\\OneDrive\\Documenti\\CV_project\\ComputerVisionProject\\Models\\paper1_models\\best_model_paper_1_20_epochs_bs_48_30k.pth', map_location=torch.device('cpu')))\n",
    "best_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "your_label_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n",
    "\n",
    "\n",
    "# Test\n",
    "test_loss, test_accuracy, test_metrics_per_class = test(best_model, test_loader, criterion, device, your_label_mapping)\n",
    "test_loss_, test_accuracy_, test_metrics_per_class_ = test(best_model, test_loader_, criterion, device, your_label_mapping)\n",
    "\n",
    "# Print metrics per class per il test set\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Loss: {test_loss_:.4f}, Test Accuracy: {test_accuracy_:.4f}')\n",
    "\n",
    "for idx, label in your_label_mapping.items():\n",
    "    print(f'{label}: Test Precision: {test_metrics_per_class[idx][\"precision\"]:.4f}, Test Recall: {test_metrics_per_class[idx][\"recall\"]:.4f}, Test F1: {test_metrics_per_class[idx][\"f1\"]:.4f}, Test Support: {test_metrics_per_class[idx][\"support\"]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
